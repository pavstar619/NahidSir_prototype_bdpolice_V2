{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NahidSir_ACLED_Prototype.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRW0kWH588lP5+MvR9hOSb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavstar619/NahidSir_prototype_bdpolice_V2/blob/main/NahidSir_ACLED_Prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXrIvym_FUqv"
      },
      "source": [
        "Note: \n",
        "\n",
        "* Acled xlsx event type had some different worded rows. Fixed that after making the first total counts xlsx\n",
        "\n",
        "* (SOLVED) Tried Specific events by separate years with cities. Didnt work out due to each city having unequal amount of events\n",
        "\n",
        "  * (SOLVED) Tried using dictionary but lots of empty arrays as one city might not have any crimes at all for one year. Not sure how to append dict to excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChDHnWza714w",
        "outputId": "dec2ac55-5746-44d6-97c0-65f72012e383"
      },
      "source": [
        "!pip install XlsxWriter\n",
        "!pip install scikit-multilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: XlsxWriter in /usr/local/lib/python3.7/dist-packages (1.4.3)\n",
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.7/dist-packages (0.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNWsqwkyfoIJ"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import folium\n",
        "\n",
        "from geopy.geocoders import Nominatim, OpenMapQuest\n",
        "from geopy.exc import GeocoderTimedOut\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_uDtTnpUAHu"
      },
      "source": [
        "# !pip install geopy\n",
        "# !pip install folium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z82cj9MeRU1",
        "outputId": "37fefe54-d6ab-4b04-9692-ad964096e108"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM8ZeogDfJas",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "10a15e5c-7558-4495-97ab-e3efcc61c4ed"
      },
      "source": [
        "# data = pd.read_excel('ACLED_Data_Prototype.xlsx')\n",
        "data = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Datasets/ACLED_Data_PrototypeV2.1.xlsx')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>DISTRICT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Lohagara</td>\n",
              "      <td>23.1998</td>\n",
              "      <td>89.6644</td>\n",
              "      <td>NARAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Hathazari</td>\n",
              "      <td>22.5052</td>\n",
              "      <td>91.8134</td>\n",
              "      <td>CHITTAGONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rangamati</td>\n",
              "      <td>22.6432</td>\n",
              "      <td>92.1919</td>\n",
              "      <td>RANGAMATI HILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajoir</td>\n",
              "      <td>23.1878</td>\n",
              "      <td>90.0322</td>\n",
              "      <td>MADARIPUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajshahi</td>\n",
              "      <td>24.3740</td>\n",
              "      <td>88.6011</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30624</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Paba</td>\n",
              "      <td>24.4417</td>\n",
              "      <td>88.6278</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30625</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bhuapur</td>\n",
              "      <td>24.4604</td>\n",
              "      <td>89.8727</td>\n",
              "      <td>TANGAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30626</th>\n",
              "      <td>2020</td>\n",
              "      <td>Protests</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7406</td>\n",
              "      <td>90.3943</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30627</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bogra</td>\n",
              "      <td>24.8510</td>\n",
              "      <td>89.3711</td>\n",
              "      <td>BOGRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30628</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7333</td>\n",
              "      <td>90.4000</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30629 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       YEAR EVENT_TYPE   LOCATION  LATITUDE  LONGITUDE        DISTRICT\n",
              "0      2001    Battles   Lohagara   23.1998    89.6644          NARAIL\n",
              "1      2001      Riots  Hathazari   22.5052    91.8134      CHITTAGONG\n",
              "2      2001      Riots  Rangamati   22.6432    92.1919  RANGAMATI HILL\n",
              "3      2001      Riots     Rajoir   23.1878    90.0322       MADARIPUR\n",
              "4      2001      Riots   Rajshahi   24.3740    88.6011        RAJSHAHI\n",
              "...     ...        ...        ...       ...        ...             ...\n",
              "30624  2020      Riots       Paba   24.4417    88.6278        RAJSHAHI\n",
              "30625  2020      Riots    Bhuapur   24.4604    89.8727         TANGAIL\n",
              "30626  2020   Protests     Dhaka    23.7406    90.3943           DHAKA\n",
              "30627  2020      Riots      Bogra   24.8510    89.3711           BOGRA\n",
              "30628  2020      Riots     Dhaka    23.7333    90.4000           DHAKA\n",
              "\n",
              "[30629 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMZTydaegKVa",
        "outputId": "15d5c454-825d-44a6-c5b4-c3b773d4d57c"
      },
      "source": [
        "data['LOCATION'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1371"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn-e-2YfYEiL"
      },
      "source": [
        "# data.loc[0, 'LOCATION']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUlt8kD-ZR6E"
      },
      "source": [
        "Specific Event types total counts by year\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ9nzSsKhWBY"
      },
      "source": [
        "# years = data.YEAR.unique()\n",
        "# events = data.EVENT_TYPE.unique() # has duplicates same values actual values is 6 not 9\n",
        "# print(events)\n",
        "\n",
        "# totalcount_df = pd.DataFrame(columns = ['YEAR'])\n",
        "\n",
        "# for i in years:\n",
        "#   year = data.loc[data['YEAR'] == i]\n",
        "#   duplicates = year.pivot_table(index = ['EVENT_TYPE'], aggfunc ='size')\n",
        "#   print(i)\n",
        "#   print(duplicates,'\\n')\n",
        "\n",
        "#   totalcount_df = totalcount_df.append(duplicates, ignore_index=True)\n",
        "\n",
        "# totalcount_df\n",
        "\n",
        "# totalcount_df.to_csv('ACLED_totalcounts.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3V4dsYFvV1x"
      },
      "source": [
        "Total Events by year and cities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu7R9LnvnhCt"
      },
      "source": [
        "# years = data['YEAR'].unique()\n",
        "# locations = data['LOCATION'].unique()\n",
        "# events = data['EVENT_TYPE'].unique()\n",
        "\n",
        "# locations_totalcount_df = pd.DataFrame(columns = [years])\n",
        "# count = 0\n",
        "\n",
        "# for i in locations:\n",
        "#   for j in years:\n",
        "#     x = data.loc[(data['LOCATION'] == i) & (data['YEAR'] == j)]\n",
        "#     # duplicates = x.pivot_table(index = ['EVENT_TYPE'], aggfunc ='size') # enable this to show specific events like riots murder etc\n",
        "#     sum = x['EVENT_TYPE'].count()\n",
        "#     # print('~~~~~~~~~~~~~~~~~~~~~~')\n",
        "#     # print(i,j,'Total events: ',sum)\n",
        "#     # print(duplicates)\n",
        "\n",
        "#     locations_totalcount_df.loc[count,j] = sum\n",
        "\n",
        "#   count+=1\n",
        "\n",
        "# # locations_totalcount_df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIqKynl0wCHJ"
      },
      "source": [
        "# # Add cities to dataframe\n",
        "# locations_totalcount_df['LOCATION'] = locations.tolist()\n",
        "# locations_totalcount_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK8WJE3tu42I"
      },
      "source": [
        "# locations_totalcount_df.to_excel('ACLED_locations_totalcount_df.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ek_EK1BhN2-"
      },
      "source": [
        "# x = data.loc[(data['LOCATION'] == 'Hathazari') & (data['YEAR'] == 2011)]\n",
        "# x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2mXTpqfb8GE"
      },
      "source": [
        "Specific Events by years by cities (using Dictionary -> excel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLCofKy-N4pq"
      },
      "source": [
        "# years = data['YEAR'].unique()\n",
        "# locations = data['LOCATION'].unique()\n",
        "# events = data['EVENT_TYPE'].unique()\n",
        "\n",
        "# years_dict = {}\n",
        "# for i in years:\n",
        "#   location_dict = {}\n",
        "#   for j in locations:\n",
        "#     x = data.loc[(data['LOCATION'] == j) & (data['YEAR'] == i)]\n",
        "#     duplicates = x.pivot_table(index = ['EVENT_TYPE'], aggfunc ='size') # enable this to show specific events like riots murder etc\n",
        "#     event_dict = {}\n",
        "#     for event, value in duplicates.items():\n",
        "#       event_dict[event] = value \n",
        "\n",
        "#     location_dict[j] = event_dict\n",
        "\n",
        "#   years_dict[i] = location_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3OLeI-tPODg"
      },
      "source": [
        "# for i in years_dict:\n",
        "#   print(years_dict[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAI2S5FKSnZv"
      },
      "source": [
        "# writer = pd.ExcelWriter('yearwise_locations_specificevent.xlsx', engine='xlsxwriter')\n",
        "\n",
        "# yearwise_locations_specificevent = pd.DataFrame()\n",
        "# yearwise_locations_specificevent\n",
        "\n",
        "# for year in years_dict:\n",
        "#   count = 0\n",
        "#   for city in years_dict[year]:\n",
        "#     yearwise_locations_specificevent.loc[count, 'LOCATION'] = city\n",
        "\n",
        "#     x = years_dict[year][city]\n",
        "#     for event,value in x.items():\n",
        "#       yearwise_locations_specificevent.loc[count, event] = value\n",
        "#       # yearwise_locations_specificevent[str(event)].iloc[count] = value\n",
        "\n",
        "#     count+=1\n",
        "\n",
        "#     # for event in years_dict[year][city]:\n",
        "\n",
        "\n",
        "#   yearwise_locations_specificevent.to_excel(writer, sheet_name=str(year),index=False)\n",
        "\n",
        "# writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmuplMZkj4x0"
      },
      "source": [
        "Specific Events by Event Type by cities (using Dictionary -> excel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxZE0WWFkF70"
      },
      "source": [
        "# years = data['YEAR'].unique()\n",
        "# locations = data['LOCATION'].unique()\n",
        "# events = data['EVENT_TYPE'].unique()\n",
        "\n",
        "# specific_event_type_totalcount = pd.DataFrame()\n",
        "\n",
        "# writer = pd.ExcelWriter('specific_event_type_totalcount.xlsx', engine='xlsxwriter')\n",
        "\n",
        "# for k in events:\n",
        "#   count = 0\n",
        "#   for i in locations:\n",
        "#   # for j in years:\n",
        "#     # x = data.loc[(data['LOCATION'] == i) & (data['YEAR'] == j) & (data['EVENT_TYPE'] == k)]\n",
        "#     x = data.loc[(data['LOCATION'] == i) & (data['EVENT_TYPE'] == k)]\n",
        "#     # duplicates = x.pivot_table(index = ['EVENT_TYPE'], aggfunc ='size') # enable this to show specific events like riots murder etc\n",
        "#     sum = x['EVENT_TYPE'].count()\n",
        "#     # print('~~~~~~~~~~~~~~~~~~~~~~')\n",
        "#     # print(i,j,'Total events: ',sum)\n",
        "#     # print(duplicates)\n",
        "      \n",
        "\n",
        "#     specific_event_type_totalcount.loc[count,'Total'] = sum\n",
        "\n",
        "#     count+=1\n",
        "\n",
        "#   specific_event_type_totalcount.to_excel(writer, sheet_name=str(k),index=False)\n",
        "\n",
        "# writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Xzxe8CUd0i"
      },
      "source": [
        "Geo Mapping Stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2UdR40E71LG"
      },
      "source": [
        "1. Geo Map by all locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYqqwRdlUdf-"
      },
      "source": [
        "# plt.figure(figsize = (15,8))\n",
        "# sns.scatterplot(data['LATITUDE'], data['LONGITUDE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChlAL6--WheF"
      },
      "source": [
        "# lat_median = data['LATITUDE'].median() # y\n",
        "# long_median = data['LONGITUDE'].median() # x\n",
        "# print(lat_median,long_median)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HehUVH2sVhi8"
      },
      "source": [
        "# # create the map.\n",
        "# map_pickup = folium.Map(location=[lat_median, long_median], zoom_start = 6)\n",
        "\n",
        "# # adding the latitude and longitude points to the map.\n",
        "# data.apply(lambda row:folium.Circle(location=[row['LATITUDE'], row['LONGITUDE']], radius = 0.25).add_to(map_pickup), axis=1)\n",
        "\n",
        "# # optional: save the map.\n",
        "# # map_pickup.save('geomap_bd.html')\n",
        "\n",
        "# # display the map: just ask for the object representation in juypter notebook.\n",
        "# map_pickup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk4jh_Ob0fSJ"
      },
      "source": [
        "Geo Locater find districts and stuff\n",
        "\n",
        "Problems:\n",
        " * Takes too long for each of the 30000 rows (2rows/sec speed)\n",
        " * (Temp Fixed). Use 1380 rows of unique locations instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s83LL7IjvtBp"
      },
      "source": [
        "# # create the locator\n",
        "# geolocator = Nominatim(user_agent=\"GGWP\") # 120 req per min\n",
        "\n",
        "# # getting the location address\n",
        "# location = geolocator.reverse((22.3075,89.0981))\n",
        "# # location = geolocator.geocode('Dhaka')\n",
        "\n",
        "# print(location.raw)\n",
        "# # print(location.raw['address']['state_district'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "162zpaCzBZNW"
      },
      "source": [
        "\n",
        "# from geopy.geocoders import OpenMapQuest\n",
        "\n",
        "# point = '23.1998, 89.6644' #here's famous Sherlock Holmes' museum lat & lng\n",
        "\n",
        "# geolocator = OpenMapQuest(api_key='x5LPBPjUCj9CUEl4U9fUrnoLGfGv7SWk')\n",
        "# address = geolocator.reverse(point)\n",
        "# print(address[0]) # use other indexes if you want more or less detailed address scope."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUqU8UteBlE0"
      },
      "source": [
        "# # # https://stackoverflow.com/questions/31506272/geopy-too-slow-timeout-all-the-time\n",
        "# # # TIME OUT ERROR FIX\n",
        "\n",
        "# # GEO CODER FUNCTION\n",
        "# def geocode(data,i, recursion=0):\n",
        "#     # print((data.loc[i, 'LATITUDE'], data.loc[i, 'LONGITUDE']))\n",
        "#     try:\n",
        "#         return geolocator.reverse((data.loc[i, 'LATITUDE'], data.loc[i, 'LONGITUDE']))\n",
        "#     except GeocoderTimedOut as e:\n",
        "#         if recursion > 10:      # max recursions\n",
        "#             raise e\n",
        "\n",
        "#         time.sleep(5) # wait a bit\n",
        "#         # try again\n",
        "#         return geocode(i, recursion=recursion + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ2Ix1Kp3zul"
      },
      "source": [
        "# # GEO LOCATOR FUNCTION\n",
        "# def locator(data,excelname):\n",
        "#   for i in range(len(data)):\n",
        "#     location = geolocator.reverse((data.loc[i, 'LATITUDE'], data.loc[i, 'LONGITUDE']))\n",
        "#     location = geocode(data,i)\n",
        "#     # print(location.raw)\n",
        "#     try:\n",
        "#       # all districts\n",
        "#       if location.raw['address'].__contains__('county'):\n",
        "#         data.loc[i, 'DISTRICT'] = location.raw['address']['county'] # for county key\n",
        "#       elif location.raw['address'].__contains__('state_district'):\n",
        "#         data.loc[i, 'DISTRICT'] = location.raw['address']['state_district'] # for state district key\n",
        "#       elif location.raw['address'].__contains__('city'):\n",
        "#         data.loc[i, 'DISTRICT'] = location.raw['address']['city'] \n",
        "#       else:\n",
        "#         substring = \"জেলা\" # check if substring in state value\n",
        "#         if substring in location.raw['address']['state']:\n",
        "#           data.loc[i, 'DISTRICT'] = location.raw['address']['state'] \n",
        "\n",
        "#       # all divisions\n",
        "#       # data.loc[i, 'DIVISION'] = location.raw['address']['state']\n",
        "#     except KeyError:\n",
        "#       print('not found')\n",
        "#     print(i)\n",
        "\n",
        "#   data.to_excel(excelname,index=False)\n",
        "#   data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x9ZaT427_gX"
      },
      "source": [
        "2. Geo Map by divisions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL0epL5mI2MO"
      },
      "source": [
        "# x = pd.DataFrame()\n",
        "# x = data.drop_duplicates(['LOCATION'])[['LOCATION','LATITUDE','LONGITUDE']]\n",
        "# x = x.reset_index(drop=True)\n",
        "# x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48JRijaqEKLI"
      },
      "source": [
        "# locator(x, 'location_by_division.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1aPKvfOOZyg"
      },
      "source": [
        "# RUN FOREVER WITHOUT DISCONNECT \n",
        "# while True:pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSqgH3F4sI-o"
      },
      "source": [
        "Classification Note:\n",
        " * Predict using Year,City - Find coords and event type(idk how)\n",
        " * Predict using Year, City - Find only event type (multiple events in one city how to handle?) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf31jjEcd2-N"
      },
      "source": [
        "1. Classify years with events only\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-WXIHVPgpYV"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import linear_model \n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGqX6QNXd2q_"
      },
      "source": [
        "# data = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Data Outputs/ACLED_event_totalcounts.xlsx')\n",
        "# data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "552OZvsSfhFC"
      },
      "source": [
        "# def R2_calc(pred_y, test_y): # Closer to 1 better score\n",
        "#   return r2_score(pred_y, test_y)\n",
        "\n",
        "# def MSE_calc(pred_y, test_y): # Lower the better\n",
        "#   return mean_squared_error(pred_y, test_y, squared = False)\n",
        "  \n",
        "# def MAE_calc(pred_y, test_y): # Lower the better\n",
        "#   return mean_absolute_error(pred_y, test_y)\n",
        "\n",
        "# def Error_calc(pred_y, test_y):\n",
        "#   return (pred_y - test_y) / test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4TkXcc0fUJw"
      },
      "source": [
        "# def modelizeall(dmp, dmp_2018):\n",
        "#   # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
        "#   writer = pd.ExcelWriter('ACLED_event_totalcounts_test_pred_data.xlsx', engine='xlsxwriter')\n",
        "#   # writer1 = pd.ExcelWriter('Without2018train_errors_data.xlsx', engine='xlsxwriter')\n",
        "\n",
        "#   model = Sequential()\n",
        "#   model.add(Dense(8, input_dim=1, activation='relu'))\n",
        "#   model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
        "#   model.add(Dense(1, kernel_initializer='normal'))\n",
        "#   # used binary loss function \n",
        "#   model.compile(loss='mse', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "#   # print(model.summary())\n",
        "\n",
        "#   # dmp_x = dmp.loc[:, dmp.columns != 'Robbery']\n",
        "#   # dmp_y = dmp['Robbery']\n",
        "#   for col in dmp.columns[1:].unique():\n",
        "#     print('~~~~~~~~~~~~~~~~~~~~~', col, '~~~~~~~~~~~~~~~~~~~~~')\n",
        "#     dmp_x = dmp['YEAR'].values\n",
        "#     dmp_y = dmp[col].values\n",
        "\n",
        "#     # ASSIGN MANUALLY\n",
        "#     train_x = dmp_x\n",
        "#     train_y = dmp_y\n",
        "\n",
        "#     test_x = dmp_2018['YEAR'].values\n",
        "#     test_y = dmp_2018[col].values\n",
        "\n",
        "\n",
        "#     # train_x, test_x, train_y, test_y = train_test_split(dmp_x, dmp_y, test_size = 0.25, random_state=0)\n",
        "\n",
        "#     # Standard scaling\n",
        "#     ss = StandardScaler()\n",
        "#     ss.fit(train_x.reshape(-1, 1))\n",
        "#     alpha_train_x = ss.transform(train_x.reshape(-1, 1))\n",
        "#     ss_test_x = ss.transform(test_x.reshape(-1, 1))\n",
        "\n",
        "#     # print(train_x)\n",
        "#     # print(test_x)\n",
        "\n",
        "\n",
        "\n",
        "#     # pred for single data\n",
        "#     Xnew = [[2021]]\n",
        "#     # print(len(Xnew[0]))\n",
        "#     # print(len(dmp_x.columns))\n",
        "\n",
        "#     regressor = DecisionTreeRegressor(random_state=0)\n",
        "#     forest = RandomForestRegressor(max_depth=2, random_state=0)\n",
        "#     svr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
        "#     mlp = MLPClassifier(random_state=0, max_iter = 2000)\n",
        "#     lasso = linear_model.Lasso(alpha=0.1)\n",
        "#     bayesian = linear_model.BayesianRidge()\n",
        "#     ridge = linear_model.Ridge()\n",
        "#     lr = LinearRegression()\n",
        "\n",
        "#     regressor.fit(train_x.reshape(-1, 1),train_y)  \n",
        "#     forest.fit(train_x.reshape(-1, 1),train_y) \n",
        "#     svr.fit(train_x.reshape(-1, 1),train_y)\n",
        "#     mlp.fit(alpha_train_x.reshape(-1,1),train_y) \n",
        "#     lasso.fit(train_x.reshape(-1,1),train_y) \n",
        "#     bayesian.fit(train_x.reshape(-1,1),train_y) \n",
        "#     ridge.fit(train_x.reshape(-1,1),train_y) \n",
        "#     lr.fit(train_x.reshape(-1,1),train_y)\n",
        "#     model.fit(train_x,train_y, epochs=30, batch_size=2)\n",
        "\n",
        "\n",
        "\n",
        "#     pred_y = regressor.predict(test_x.reshape(-1, 1))\n",
        "#     pred_y1 = forest.predict(test_x.reshape(-1, 1)) \n",
        "#     pred_y2 = svr.predict(test_x.reshape(-1, 1)) \n",
        "#     pred_y3 = mlp.predict(ss_test_x.reshape(-1, 1))\n",
        "#     pred_y4 = lasso.predict(test_x.reshape(-1,1))\n",
        "#     pred_y5 = bayesian.predict(test_x.reshape(-1,1))\n",
        "#     pred_y6 = ridge.predict(test_x.reshape(-1,1))\n",
        "#     pred_y7 = lr.predict(test_x.reshape(-1,1))\n",
        "#     pred_y8 = model.predict(test_x.reshape(-1,1)).tolist()\n",
        "\n",
        "#     # error_y = (pred_y - test_y) / test_y #lower the better\n",
        "#     # error_y1 = (pred_y1 - test_y) / test_y\n",
        "#     # error_y2 = (pred_y2 - test_y) / test_y\n",
        "#     # error_y3 = (pred_y3 - test_y) / test_y\n",
        "#     # error_y4 = (pred_y4 - test_y) / test_y\n",
        "#     # error_y5 = (pred_y5 - test_y) / test_y\n",
        "#     # error_y6 = (pred_y6 - test_y) / test_y\n",
        "#     # error_y7 = (pred_y7 - test_y) / test_y\n",
        "\n",
        "#     pred_y_list = [pred_y,pred_y1,pred_y2,pred_y3,pred_y4,pred_y5,pred_y6,pred_y7,pred_y8]\n",
        "#     error_y_list = []\n",
        "#     r2_y_list = []\n",
        "#     mse_y_list = []\n",
        "#     mae_y_list = []\n",
        "\n",
        "#     for pred_y in pred_y_list:\n",
        "#       # error_y = Error_calc(pred_y,test_y)\n",
        "#       # error_y_list.append(error_y)\n",
        "\n",
        "#       r2_y = R2_calc(pred_y,test_y)\n",
        "#       r2_y_list.append(r2_y)\n",
        "\n",
        "#       mse_y = MSE_calc(pred_y,test_y)\n",
        "#       mse_y_list.append(mse_y)\n",
        "\n",
        "#       mae_y = MAE_calc(pred_y,test_y)\n",
        "#       mae_y_list.append(mae_y)\n",
        "\n",
        "#     Xpred_y = mlp.predict(Xnew) #one data only\n",
        "\n",
        "#     model_list = ['Decision Tree', 'Random Forest', 'SVR', 'MLP(Adam)', 'Lasso', 'Bayesian', 'Ridge', 'Linear Regression','Neural Net']\n",
        "#     # print('~~~~ Test Val || Predicted Val || Errors: R2, RMSE, MAE ~~~~')\n",
        "#     # for i in range(len(pred_y_list)):\n",
        "#     #   print(model_list[i], 'Test Val: ',test_y, 'Predicted Val: ', pred_y_list[i], 'Errors R2 | RMSE | MAE: ', r2_y_list[i], mse_y_list[i], mae_y_list[i]) # Dont show Metric as only one test row\n",
        "\n",
        "\n",
        "#     # # Put in dataframes\n",
        "#     # errors_data = pd.DataFrame(list(zip(model_list, r2_y_list, mse_y_list, mae_y_list)),\n",
        "#     #            columns =['Algorithms','R2 Score','Mean Square Error(MSE)','Mean Absolute Error(MAE)'])\n",
        "#     # # print(errors_data)\n",
        "#     test_pred_data = pd.DataFrame(columns =['Algorithms','Test Years','Test Values','Predicted Values','R2 Score','Mean Square Error(MSE)','Mean Absolute Error(MAE)'])\n",
        "#     for i in range(len(pred_y_list)):\n",
        "#       test_pred_data.loc[i] = [model_list[i], test_x, test_y, list(np.around(pred_y_list[i],2)), r2_y_list[i], mse_y_list[i], mae_y_list[i]]\n",
        "#     # print(test_pred_data)\n",
        "\n",
        "\n",
        "#     # Put in excel sheets\n",
        "#     # Write each dataframe to a different worksheet.\n",
        "#     test_pred_data.to_excel(writer, sheet_name=col,index=False)\n",
        "#     # errors_data.to_excel(writer1, sheet_name=col,index=False)\n",
        "\n",
        "\n",
        "#     # Xpred_y = mlp.predict(Xnew) #one data only\n",
        "\n",
        "\n",
        "#     # m2_y = mean_squared_error(test_y,pred_y, squared=False)\n",
        "\n",
        "#     # print('~~~~ Test Val || Predicted Val || Errors: R2, RMSE, RSE ~~~~')\n",
        "#     # # print(test_y)\n",
        "#     # print('Test DT: ',test_y,pred_y,error_y) # Decision Tree\n",
        "#     # print('Test RF: ',test_y,pred_y1,error_y1) # Random Forest\n",
        "#     # print('Test SVR: ',test_y,pred_y2,error_y2) # SVM\n",
        "#     # print('Test MLP: ',test_y,pred_y3,error_y3) # mlp\n",
        "#     # print('Test Lasso: ',test_y,pred_y4,error_y4) # lasso\n",
        "#     # print('Test Bayesian: ',test_y,pred_y5,error_y5) # bayesian\n",
        "#     # print('Test Ridge: ',test_y,pred_y6,error_y6) # ridge\n",
        "#     # print('Test Linear Regression: ',test_y,pred_y7,error_y7) # lr\n",
        "\n",
        "#     # print('2018 BEST MLP: ',test_y,pred_y3) # Decision Tree\n",
        "#     print(Xnew,'BEST MLP: ',col,Xpred_y) # Decision Tree\n",
        "\n",
        "\n",
        "#   # Close the Pandas Excel writer and output the Excel file.\n",
        "#   writer.save()\n",
        "#   # writer1.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRZZnCMlfNFr"
      },
      "source": [
        "# # 2018 dmp\n",
        "# dmp_2018 = data.iloc[19:] # 2020\n",
        "# print(dmp_2018)\n",
        "\n",
        "# # 2010 to 2017\n",
        "# dmp_till2017 = data.drop(19)\n",
        "# print(dmp_till2017)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU46Yow0j-WJ"
      },
      "source": [
        "# modelizeall(dmp_till2017, dmp_2018)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz5xZ01U3DQr"
      },
      "source": [
        "1.1 Predict 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEDWRGeakpHA"
      },
      "source": [
        "# dmp = data\n",
        "# # MODELIZE 2021\n",
        "# for col in data.columns[1:].unique():\n",
        "#   print('~~~~~~~~~~~~~~~~~~~~~', col, '~~~~~~~~~~~~~~~~~~~~~')\n",
        "#   dmp_x = dmp['YEAR'].values\n",
        "#   dmp_y = dmp[col].values\n",
        "\n",
        "#   # ASSIGN MANUALLY\n",
        "#   train_x = dmp_x\n",
        "#   train_y = dmp_y\n",
        "\n",
        "#   # Standard scaling\n",
        "#   ss = StandardScaler()\n",
        "#   ss.fit(train_x.reshape(-1, 1))\n",
        "#   ss_train_x = ss.transform(train_x.reshape(-1, 1))\n",
        "\n",
        "\n",
        "#   # pred for single data\n",
        "#   Xnew = [[2021]]\n",
        "#   # print(len(Xnew[0]))\n",
        "#   # print(len(dmp_x.columns))\n",
        "\n",
        "#   mlp = MLPClassifier(random_state=0, max_iter = 5000)\n",
        "#   mlp.fit(ss_train_x.reshape(-1,1),train_y) \n",
        "\n",
        "#   Xpred_y = mlp.predict(Xnew) #one data only\n",
        "\n",
        "#   print(Xnew,'BEST MLP: ',col,Xpred_y) # Decision Tree\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM0KUqN528Xf"
      },
      "source": [
        "2. Multi Label Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD2ZupaKtTIP"
      },
      "source": [
        "Did: \n",
        "* Predicted Event \n",
        "* Predicted Lat,long \n",
        "* Predicted Location\n",
        "\n",
        "Left: \n",
        "* Predict Lat, Long, Event\n",
        "\n",
        "Problem:\n",
        "* Low precisions\n",
        "\n",
        "BREAKTHROUGH:\n",
        "* (FAILED cant read y data) IMPROVED MSE from 0.95 to 0.18 by scaling the y data. R2 from 0.2 to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXXnaYbjL2Ud"
      },
      "source": [
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-nxHHDB3KxR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "253860ac-ac30-4492-bd77-8ddac2a453cf"
      },
      "source": [
        "data = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Datasets/ACLED_Data_PrototypeV2.1.xlsx')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>DISTRICT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Lohagara</td>\n",
              "      <td>23.1998</td>\n",
              "      <td>89.6644</td>\n",
              "      <td>NARAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Hathazari</td>\n",
              "      <td>22.5052</td>\n",
              "      <td>91.8134</td>\n",
              "      <td>CHITTAGONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rangamati</td>\n",
              "      <td>22.6432</td>\n",
              "      <td>92.1919</td>\n",
              "      <td>RANGAMATI HILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajoir</td>\n",
              "      <td>23.1878</td>\n",
              "      <td>90.0322</td>\n",
              "      <td>MADARIPUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajshahi</td>\n",
              "      <td>24.3740</td>\n",
              "      <td>88.6011</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30624</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Paba</td>\n",
              "      <td>24.4417</td>\n",
              "      <td>88.6278</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30625</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bhuapur</td>\n",
              "      <td>24.4604</td>\n",
              "      <td>89.8727</td>\n",
              "      <td>TANGAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30626</th>\n",
              "      <td>2020</td>\n",
              "      <td>Protests</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7406</td>\n",
              "      <td>90.3943</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30627</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bogra</td>\n",
              "      <td>24.8510</td>\n",
              "      <td>89.3711</td>\n",
              "      <td>BOGRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30628</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7333</td>\n",
              "      <td>90.4000</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30629 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       YEAR EVENT_TYPE   LOCATION  LATITUDE  LONGITUDE        DISTRICT\n",
              "0      2001    Battles   Lohagara   23.1998    89.6644          NARAIL\n",
              "1      2001      Riots  Hathazari   22.5052    91.8134      CHITTAGONG\n",
              "2      2001      Riots  Rangamati   22.6432    92.1919  RANGAMATI HILL\n",
              "3      2001      Riots     Rajoir   23.1878    90.0322       MADARIPUR\n",
              "4      2001      Riots   Rajshahi   24.3740    88.6011        RAJSHAHI\n",
              "...     ...        ...        ...       ...        ...             ...\n",
              "30624  2020      Riots       Paba   24.4417    88.6278        RAJSHAHI\n",
              "30625  2020      Riots    Bhuapur   24.4604    89.8727         TANGAIL\n",
              "30626  2020   Protests     Dhaka    23.7406    90.3943           DHAKA\n",
              "30627  2020      Riots      Bogra   24.8510    89.3711           BOGRA\n",
              "30628  2020      Riots     Dhaka    23.7333    90.4000           DHAKA\n",
              "\n",
              "[30629 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp5jIDTlp712"
      },
      "source": [
        "2.1 Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa2bghDcTSin"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from pandas.api.types import is_string_dtype\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "\n",
        "# evaluate multioutput regression model with k-fold cross-validation\n",
        "from numpy import absolute\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7_hwtDM3rLU"
      },
      "source": [
        "# x = data.copy()\n",
        "# x = x.drop('YEAR',axis=1)\n",
        "# x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_crY-gUTL6LN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a7b88f4-8466-4181-bcef-8dcf6e0d51f8"
      },
      "source": [
        "x = data[['YEAR','LOCATION']]\n",
        "# x = data[['YEAR','LOCATION','LATITUDE','LONGITUDE']]\n",
        "# x = x.drop('EVENT_TYPE', axis = 1)\n",
        "y = data[['LATITUDE','LONGITUDE','EVENT_TYPE']]\n",
        "# y = data[['EVENT_TYPE']]\n",
        "\n",
        "# x = data.loc[:, data.columns != ('EVENT_TYPE',)]\n",
        "# y = data.loc[:, data.columns == 'EVENT_TYPE']\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       YEAR   LOCATION\n",
            "0      2001   Lohagara\n",
            "1      2001  Hathazari\n",
            "2      2001  Rangamati\n",
            "3      2001     Rajoir\n",
            "4      2001   Rajshahi\n",
            "...     ...        ...\n",
            "30624  2020       Paba\n",
            "30625  2020    Bhuapur\n",
            "30626  2020     Dhaka \n",
            "30627  2020      Bogra\n",
            "30628  2020     Dhaka \n",
            "\n",
            "[30629 rows x 2 columns]\n",
            "       LATITUDE  LONGITUDE EVENT_TYPE\n",
            "0       23.1998    89.6644    Battles\n",
            "1       22.5052    91.8134      Riots\n",
            "2       22.6432    92.1919      Riots\n",
            "3       23.1878    90.0322      Riots\n",
            "4       24.3740    88.6011      Riots\n",
            "...         ...        ...        ...\n",
            "30624   24.4417    88.6278      Riots\n",
            "30625   24.4604    89.8727      Riots\n",
            "30626   23.7406    90.3943   Protests\n",
            "30627   24.8510    89.3711      Riots\n",
            "30628   23.7333    90.4000      Riots\n",
            "\n",
            "[30629 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxjVoeVW-hQW"
      },
      "source": [
        "# USE THIS OTHERWISE LE.FIT CAUSES PROBLEMS\n",
        "unique_events = data['EVENT_TYPE'].unique()\n",
        "unique_locations = data['LOCATION'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca56odIXlnqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf52d23-c5f9-428a-8d4f-152b07a76220"
      },
      "source": [
        "# x_numpy = x.to_numpy()\n",
        "# y_numpy = y.to_numpy()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)\n",
        "# stratify=y_numpy\n",
        "\n",
        "y1_train = y_train[['LATITUDE','LONGITUDE']]\n",
        "y2_train = y_train[['EVENT_TYPE']]\n",
        "\n",
        "y1_test = y_test[['LATITUDE','LONGITUDE']]\n",
        "y2_test = y_test[['EVENT_TYPE']]\n",
        "\n",
        "\n",
        "# MULTI OUTPUT REGRESSION MODELS: LinearRegression, KNeighborsRegressor, DecisionTreeRegressor,RandomForestRegressor\n",
        "\n",
        "# clf_models = [\n",
        "#           ('MLP', make_pipeline(StandardScaler(), MLPClassifier())),\n",
        "#           # ('Linear Regression', LinearRegression()),\n",
        "#           ('Random Forest', RandomForestClassifier()),\n",
        "#           # ('Decision Tree', DecisionTreeClassifier()),\n",
        "#           ('SVM', make_pipeline(StandardScaler(), SVC())),\n",
        "#           ('KNN', make_pipeline(StandardScaler(), KNeighborsClassifier())),\n",
        "#           # ('Naive Bayes',GaussianNB()),\n",
        "#           # ('Logistics Regression', LogisticRegression()),\n",
        "#           # ('Stochastic Gradient Descent', SGDClassifier()),\n",
        "#           # ('LightGBM', LGBMClassifier()),\n",
        "#           # ('AdaBoost', AdaBoostClassifier()),\n",
        "#           # ('XGBoost', XGBClassifier())\n",
        "#           ]\n",
        "\n",
        "models = [\n",
        "               ('Decisions Tree', DecisionTreeRegressor(), DecisionTreeClassifier()),\n",
        "               ('MLP', make_pipeline(StandardScaler(), MLPRegressor()), make_pipeline(StandardScaler(), MLPClassifier())),\n",
        "               ('Random Forest', RandomForestRegressor(), RandomForestClassifier()),\n",
        "               ('SVM', MultiOutputRegressor(make_pipeline(StandardScaler(), SVR())), make_pipeline(StandardScaler(), SVC())),\n",
        "               ('KNN', make_pipeline(StandardScaler(), KNeighborsRegressor()), make_pipeline(StandardScaler(), KNeighborsClassifier()))\n",
        "               ]\n",
        "\n",
        "# single  = [2021, 15, 24, 89]\n",
        "\n",
        "# ms = MinMaxScaler()\n",
        "# ms = StandardScaler()\n",
        "le = LabelEncoder()\n",
        "\n",
        "# le.fit(train_y)\n",
        "# train_y = le.transform(train_y)\n",
        "# test_y = le.transform(test_y)\n",
        "\n",
        "ms_train_x = pd.DataFrame()\n",
        "ms_test_x = pd.DataFrame()\n",
        "\n",
        "# # LABEL ENCODER + Min max Scaler\n",
        "# for col in x_train.columns:\n",
        "#   if (is_string_dtype(x_train[col].dtype)):\n",
        "#     uniques = data[col].unique() # Do this otherwise test doesnt get enough labels to labelencode\n",
        "#     le.fit(uniques)\n",
        "#     ms_train_x[col] = le.transform(x_train[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "#     ms_test_x[col] = le.transform(x_test[[col]]).flatten()\n",
        "\n",
        "#   else:\n",
        "#     ms.fit(x_train[[col]])\n",
        "#     ms_train_x[col] = x_train[col].copy() # flatten otherwise 1d doesnt work as numpy array\n",
        "#     ms_test_x[col] = x_test[col].copy()\n",
        "\n",
        "\n",
        "for col in x_train.columns:\n",
        "  if (is_string_dtype(x_train[col].dtype)):\n",
        "    if col == 'LOCATION': # TOO MANY LOCATIONS\n",
        "      uniques = data['LOCATION'].unique()\n",
        "      le.fit(uniques)\n",
        "      ms_train_x[col] = le.transform(x_train[col].values.reshape(-1, 1))\n",
        "      ms_test_x[col] = le.transform(x_test[col].values.reshape(-1, 1))\n",
        "    else:\n",
        "      ms_train_x[col] = le.fit_transform(x_train[col].values.reshape(-1, 1))\n",
        "      ms_test_x[col] = le.transform(x_test[col].values.reshape(-1, 1))\n",
        "  else:\n",
        "    # ms.fit(x_train[[col]])\n",
        "    ms_train_x[col] = x_train[col].copy()\n",
        "    ms_test_x[col] = x_test[col].copy()\n",
        "\n",
        "\n",
        "# print(ms_train_x)\n",
        "# print(ms_test_x)\n",
        "\n",
        "# y2 test encode:\n",
        "le.fit(y2_train)\n",
        "le_y2_train = le.transform(y2_train)\n",
        "le_y2_test = le.transform(y2_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ useless code # all to use\n",
        "# # PREPROCESS LOCATION\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# le.fit(unique_events)\n",
        "# x_train[:,1] = le.transform(x_train[:,1]) # Events\n",
        "# x_test[:,1] = le.transform(x_test[:,1])\n",
        "# print(le.classes_)\n",
        "\n",
        "\n",
        "# le.fit(unique_locations)\n",
        "# x_train[:,2] = le.transform(x_train[:,2]) # Locations\n",
        "# x_test[:,2] = le.transform(x_test[:,2])\n",
        "# print(le.classes_)\n",
        "# # x_train.loc[:, ('LOCATION')] = le.transform(x_train.loc[:, ('LOCATION')]) # IMPORTANT: USE .loc instead of direct ['LOCATION'] otherwise chain indexing error\n",
        "# # x_test.loc[:, ('LOCATION')] = le.transform(x_test.loc[:, ('LOCATION')])\n",
        "# # print(x['LOCATION'])\n",
        "# # single[1] = le.transform(single[1])\n",
        "\n",
        "\n",
        "# # df = pd.DataFrame(single)\n",
        "# # df.loc[1] = le.transform(df.loc[1].values)\n",
        "# # single = df.values.tolist()\n",
        "\n",
        "\n",
        "# # PREPROCESS Y LABELS\n",
        "# # le2 = LabelEncoder()\n",
        "# # le2.fit(unique_events)\n",
        "# # y_train = le2.transform(y_train)\n",
        "# # y_test = le2.transform(y_test)\n",
        "# # print(le2.classes_)\n",
        "\n",
        "# # STANDARD SCALE X Attributes\n",
        "# ss = StandardScaler()\n",
        "# ss.fit(x_train)\n",
        "# x_train = ss.transform(x_train)\n",
        "# x_test = ss.transform(x_test)\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ useless code\n",
        "\n",
        "\n",
        "\n",
        "# df = ss.transform(df)\n",
        "# single = df.values.tolist()\n",
        "\n",
        "\n",
        "for name, model1, model2 in models:\n",
        "  regr = model1.fit(ms_train_x, y1_train)\n",
        "  clf = model2.fit(ms_train_x, le_y2_train)\n",
        "\n",
        "  predictions1 = regr.predict(ms_test_x)\n",
        "  predictions2 = clf.predict(ms_test_x)\n",
        "\n",
        "  # single_pred = clf.predict([single])\n",
        "\n",
        "  print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "  print(name)\n",
        "  # print(single_pred)\n",
        "  # print(predictions)\n",
        "  print('R2 Score: ', r2_score(y1_test, predictions1), 'MSE: ', mean_squared_error(y1_test, predictions1, squared= False))\n",
        "\n",
        "  print('Precision | Recall | F1 Score | Support')\n",
        "  print(precision_recall_fscore_support(le_y2_test, predictions2, average='weighted', labels=np.unique(predictions2))) # why did i use np.unique()??\n",
        "  # print(classification_report(y_test,predictions, target_names=(le.classes_).tolist()))\n",
        "  # print(classification_report(y_test,predictions, target_names=(le.classes_).tolist()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Decisions Tree\n",
            "R2 Score:  0.9291274770643767 MSE:  0.2565410467242627\n",
            "Precision | Recall | F1 Score | Support\n",
            "(0.4863837622125432, 0.5131888221467746, 0.49363628352168337, None)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "MLP\n",
            "R2 Score:  0.060565064777737265 MSE:  0.9373053020833444\n",
            "Precision | Recall | F1 Score | Support\n",
            "(0.5136638719010446, 0.6997478386167147, 0.5750316721973342, None)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Random Forest\n",
            "R2 Score:  0.937310940893072 MSE:  0.24119103950150803\n",
            "Precision | Recall | F1 Score | Support\n",
            "(0.48913943385862135, 0.5180203708540089, 0.497784660962168, None)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "SVM\n",
            "R2 Score:  0.05498278615011587 MSE:  0.9402540998725188\n",
            "Precision | Recall | F1 Score | Support\n",
            "(0.5004830793881864, 0.6829971181556196, 0.554728760062891, None)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "KNN\n",
            "R2 Score:  0.5619050672158261 MSE:  0.6374680563516819\n",
            "Precision | Recall | F1 Score | Support\n",
            "(0.4597729940027341, 0.4853747714808044, 0.46241472839181996, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqu3LVzEp071"
      },
      "source": [
        "2.2 Whole data as input: Did regr and clf separate predictions same input\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtbSFFzlqiq6"
      },
      "source": [
        "# data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XegsC3asehVu"
      },
      "source": [
        "# x = data[['YEAR','LOCATION']]\n",
        "# y1 = data[['LATITUDE','LONGITUDE']]\n",
        "# y2 = data[['EVENT_TYPE']]\n",
        "# print(x)\n",
        "# print(y1)\n",
        "# print(y2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWtsxxTJrHZn"
      },
      "source": [
        "# # model_regr = make_pipeline(StandardScaler(), RandomForestRegressor())\n",
        "# # model_clf = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
        "# model_regr = RandomForestRegressor()\n",
        "# model_clf = RandomForestClassifier()\n",
        "\n",
        "# ms_train_x = pd.DataFrame()\n",
        "\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# # # LABEL ENCODER + Min max Scaler ~~ Training Data ~~ \n",
        "# for col in x.columns:\n",
        "#   if (is_string_dtype(x[col].dtype)):\n",
        "#     uniques = data[col].unique() # Do this otherwise test doesnt get enough labels to labelencode\n",
        "#     le.fit(uniques)\n",
        "#     ms_train_x[col] = le.transform(x[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "#   else:\n",
        "#     ms_train_x[col] = x[col].copy() # flatten otherwise 1d doesnt work as numpy array\n",
        "#     # ms.fit(x[[col]])\n",
        "#     # ms_train_x[col] = ms.transform(x[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "\n",
        "# Xnew = [[2021, 'Dhaka'],[2021,'Barisal']]\n",
        "# df_Xnew = pd.DataFrame(Xnew, columns = ['YEAR', 'LOCATION'])\n",
        "\n",
        "# ms_df_Xnew = pd.DataFrame()\n",
        "\n",
        "# # # LABEL ENCODER + Min max Scaler ~~ Single Datas ~~\n",
        "# for col in df_Xnew.columns:\n",
        "#   if (is_string_dtype(df_Xnew[col].dtype)):\n",
        "#     ms_df_Xnew[col] = le.transform(df_Xnew[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "#   else:\n",
        "#     ms_df_Xnew[col] = df_Xnew[col].copy() # flatten otherwise 1d doesnt work as numpy array\n",
        "#     # ms_df_Xnew[col] = ms.transform(df_Xnew[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "\n",
        "# # Label Encoder Test Data \n",
        "# uniques = y2['EVENT_TYPE'].unique()\n",
        "# le.fit(uniques)\n",
        "# le_y2 = le.transform(y2['EVENT_TYPE'])\n",
        "# # Xnew[1] = le.transform(Xnew[1])\n",
        "# # print(le_y2)\n",
        "\n",
        "# # print(ms_train_x)\n",
        "# # print(y1)\n",
        "# # print(y2)\n",
        "\n",
        "# model_regr.fit(ms_train_x, y1)\n",
        "# model_clf.fit(ms_train_x,y2)\n",
        "\n",
        "# pred_regr = model_regr.predict(ms_df_Xnew)\n",
        "# pred_clf = model_clf.predict_proba(ms_df_Xnew)\n",
        "\n",
        "# print('~~ Probability Classes ~~ : ', model_clf.classes_)\n",
        "\n",
        "# for i in range(len(pred_regr)):\n",
        "#   print('Test Data: ',Xnew[i])\n",
        "#   print('Predicted Data: ',pred_regr[i],pred_clf[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr5L05wkZ7ip"
      },
      "source": [
        "** DONT NEED THIS SECTION ANYMORE\n",
        "\n",
        "Problem:\n",
        " * Only 5 labels shown but should be 6 events\n",
        "\n",
        "Ideas:\n",
        "* try adding more col in train y\n",
        "* do the 3 col preds separtely or coord at once then append result\n",
        "* do the lat long first. Add to dataset then do the event type\n",
        "\n",
        "Solve: \n",
        "* 2 ways to solve this https://machinelearningmastery.com/multi-output-regression-models-with-python/. Another problem arises since event type is classification and location is regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdXNrp24bONZ"
      },
      "source": [
        "# x = data.loc[:, data.columns != 'EVENT_TYPE']\n",
        "# y = data['EVENT_TYPE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fou5Oiq0Nvey"
      },
      "source": [
        "# data['EVENT_TYPE'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QskWuIlJM20w"
      },
      "source": [
        "# # x, y = make_multilabel_classification(n_samples = len(data['EVENT_TYPE'].unique()), random_state=0,return_indicator=False)\n",
        "# # this will generate a random multi-label dataset\n",
        "# x, y = make_multilabel_classification(sparse = True, n_labels = 6, return_indicator = 'sparse', allow_unlabeled = False)\n",
        "# # print(x)\n",
        "# # print(y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awc95A1YPT_J"
      },
      "source": [
        "# # using binary relevance\n",
        "# from skmultilearn.problem_transform import BinaryRelevance\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# , x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# # initialize binary relevance multi-label classifier\n",
        "# # with a gaussian naive bayes base classifier\n",
        "# classifier = BinaryRelevance(GaussianNB())\n",
        "\n",
        "# # train\n",
        "# classifier.fit(, y_train)\n",
        "\n",
        "# # predict\n",
        "# predictions = classifier.predict(x_test)\n",
        "# print(predictions.toarray())\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# print(classification_report(y_test.toarray(),predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QHwkYjcRZ84"
      },
      "source": [
        "3. Predict Total Events by district"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cik51HxdRmJB"
      },
      "source": [
        "Instructions:\n",
        "1. Join Districts\n",
        "2. Drop Rows of West Bengal\n",
        "3. Input Year, District, Event Type. Output Lat,long, Total Count Specific Event"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbqKu4EFRZw5"
      },
      "source": [
        "# # DISTRICTS\n",
        "# data2 = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Data Outputs/ACLED_location_by_district_V2.xlsx')\n",
        "# data2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEWcmq41zCM3"
      },
      "source": [
        "Join Districts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1Os_MwQS0Jb"
      },
      "source": [
        "# # 1. JOIN DISTRICTS\n",
        "\n",
        "# # count = 0\n",
        "# # for i in range(len(data.index)):\n",
        "# #   for j in range(len(data2.index)):\n",
        "# #     if(data['LOCATION'][i] == data2['LOCATION'][j]):\n",
        "# #       data.loc[i, 'DISTRICT'] = data2['CAPITALIZED'][j]\n",
        "# #   count+=1\n",
        "# #   print(count)\n",
        "\n",
        "# tempdata = data\n",
        "\n",
        "# count = 0\n",
        "# locations = data2['LOCATION'].unique()\n",
        "\n",
        "# for location in locations:\n",
        "#   temp = data.loc[(data['LOCATION'] == location)]\n",
        "#   for i in temp.index:\n",
        "#     for j in range(len(data2.index)):\n",
        "#       if data2.loc[j, 'LOCATION'] == location:\n",
        "#         tempdata.loc[i, 'DISTRICT'] = data2.loc[j,'CAPITALIZED']\n",
        "    \n",
        "#     count+=1\n",
        "#     print(count)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUidgeeoc-Sq"
      },
      "source": [
        "# # CHECK IF ANY NULL VAL\n",
        "# tempdata.isnull().values.any()\n",
        "\n",
        "# is_NaN = tempdata.isnull()\n",
        "# row_has_NaN = is_NaN.any(axis=1)\n",
        "# rows_with_NaN = tempdata[row_has_NaN]\n",
        "# for i in rows_with_NaN['LOCATION']:\n",
        "#   print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iZRrpMK9g8K"
      },
      "source": [
        "# for i in rows_with_NaN.index:\n",
        "#   if rows_with_NaN.loc[i, 'LOCATION'] == 'Dhaka':\n",
        "#     tempdata.loc[i,'DISTRICT'] == 'DHAKA'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MggROCBTcm13"
      },
      "source": [
        "# # # # ADD DHAKA AS MISSING VAL\n",
        "# tempdata.fillna(value = 'DHAKA', inplace = True)\n",
        "# # # tempdata.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC-XkAIr_6fB"
      },
      "source": [
        "# tempdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY1-v5NXy8-k"
      },
      "source": [
        "# tempdata.to_excel('ACLED_Data_PrototypeV2.1.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI9V-DXCy9ad"
      },
      "source": [
        "Dataset generator for specific event counts\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XqbXSKJqVuIw",
        "outputId": "0cf3518e-5641-40ce-f15f-75f480149ee1"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>DISTRICT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Lohagara</td>\n",
              "      <td>23.1998</td>\n",
              "      <td>89.6644</td>\n",
              "      <td>NARAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Hathazari</td>\n",
              "      <td>22.5052</td>\n",
              "      <td>91.8134</td>\n",
              "      <td>CHITTAGONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rangamati</td>\n",
              "      <td>22.6432</td>\n",
              "      <td>92.1919</td>\n",
              "      <td>RANGAMATI HILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajoir</td>\n",
              "      <td>23.1878</td>\n",
              "      <td>90.0322</td>\n",
              "      <td>MADARIPUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajshahi</td>\n",
              "      <td>24.3740</td>\n",
              "      <td>88.6011</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30624</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Paba</td>\n",
              "      <td>24.4417</td>\n",
              "      <td>88.6278</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30625</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bhuapur</td>\n",
              "      <td>24.4604</td>\n",
              "      <td>89.8727</td>\n",
              "      <td>TANGAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30626</th>\n",
              "      <td>2020</td>\n",
              "      <td>Protests</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7406</td>\n",
              "      <td>90.3943</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30627</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bogra</td>\n",
              "      <td>24.8510</td>\n",
              "      <td>89.3711</td>\n",
              "      <td>BOGRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30628</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7333</td>\n",
              "      <td>90.4000</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30629 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       YEAR EVENT_TYPE   LOCATION  LATITUDE  LONGITUDE        DISTRICT\n",
              "0      2001    Battles   Lohagara   23.1998    89.6644          NARAIL\n",
              "1      2001      Riots  Hathazari   22.5052    91.8134      CHITTAGONG\n",
              "2      2001      Riots  Rangamati   22.6432    92.1919  RANGAMATI HILL\n",
              "3      2001      Riots     Rajoir   23.1878    90.0322       MADARIPUR\n",
              "4      2001      Riots   Rajshahi   24.3740    88.6011        RAJSHAHI\n",
              "...     ...        ...        ...       ...        ...             ...\n",
              "30624  2020      Riots       Paba   24.4417    88.6278        RAJSHAHI\n",
              "30625  2020      Riots    Bhuapur   24.4604    89.8727         TANGAIL\n",
              "30626  2020   Protests     Dhaka    23.7406    90.3943           DHAKA\n",
              "30627  2020      Riots      Bogra   24.8510    89.3711           BOGRA\n",
              "30628  2020      Riots     Dhaka    23.7333    90.4000           DHAKA\n",
              "\n",
              "[30629 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2356
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "430mUL9Xbv5V"
      },
      "source": [
        "https://stackoverflow.com/questions/44423105/how-to-extract-column-from-python-pandas-pivot-table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4rk2z00Y6_0"
      },
      "source": [
        "# dups = data.pivot_table(index=['YEAR','EVENT_TYPE','LOCATION','DISTRICT'], columns=['YEAR','EVENT_TYPE','LOCATION','DISTRICT'], aggfunc='size').sum(axis=1).reset_index()\n",
        "# dups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmId3he7csBU"
      },
      "source": [
        "# dups.to_excel('ACLED_Data_PrototypeV4.4(locationwise).xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ARn8xSRgJIQ"
      },
      "source": [
        "# # Dataset Generator for Specific Event Counts\n",
        "# # ADD TOTALS OF each specific events per year for each col\n",
        "# # BETTER OPTIONS use later: slice thru range of year indexes in temp. Might be faster to iter. Single rows take too long to iter (DONE)\n",
        "\n",
        "# tempdata = data\n",
        "# tempdata.drop(['LONGITUDE','LATITUDE'], axis = 1)\n",
        "\n",
        "# years = data['YEAR'].unique()\n",
        "# events = data['EVENT_TYPE'].unique()\n",
        "# # districts = data['DISTRICT'].unique()\n",
        "# locations = data['LOCATION'].unique()\n",
        "\n",
        "# count = 0\n",
        "# for year in years:\n",
        "#   for location in locations:\n",
        "#     for event in events:\n",
        "#       temp = data.loc[(data['YEAR'] == year) & (data['LOCATION'] == location) & (data['EVENT_TYPE'] == event)]\n",
        "#       # print(temp)\n",
        "#       # event_tuple = temp['EVENT_TYPE'].value_counts()\n",
        "#       for i in temp.index:\n",
        "#         if data.loc[i, 'EVENT_TYPE'] == event:\n",
        "#           # for event, val in event_tuple.items():\n",
        "#           tempdata.loc[i, 'COUNT'] = len(temp.index) \n",
        "#     count+=1\n",
        "#     print(count)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtqkPpUQoIVs"
      },
      "source": [
        "# tempdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpgCelvhADsZ"
      },
      "source": [
        "# tempdata.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTdLRoULIbGV"
      },
      "source": [
        "# # FILL OUT MISSING VALS\n",
        "# tempdata.fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrVwXnUMU2FC"
      },
      "source": [
        "# tempdata.to_excel('ACLED_Data_PrototypeV4.3(locationwise).xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5viig1FJL4KQ"
      },
      "source": [
        "# # DISTRICTS\n",
        "# data2 = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Datasets/ACLED_Data_PrototypeV4.3(locationwise).xlsx')\n",
        "# data2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muSY2P3Lwz1p"
      },
      "source": [
        "Dataset generator for TOTAL event counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goatjg8Iw3ZU"
      },
      "source": [
        "# # Dataset Generator for Total Event Counts\n",
        "\n",
        "# tempdata = data2\n",
        "\n",
        "# years = data2['YEAR'].unique()\n",
        "# # events = data['EVENT_TYPE'].unique()\n",
        "# # districts = data['DISTRICT'].unique()\n",
        "# # locations = data['LOCATION'].unique()\n",
        "# temptotals = pd.DataFrame()\n",
        "\n",
        "# count = 0\n",
        "# for year in years:\n",
        "#   # for location in locations:\n",
        "#     # for event in events:\n",
        "#   temp = tempdata.loc[(tempdata['YEAR'] == year)]\n",
        "#   temptotals.loc[count, 'YEAR'] = year\n",
        "#   temptotals.loc[count, 'TOTAL'] = temp['COUNT'].sum()\n",
        "#   count+=1\n",
        "#     #   # print(temp)\n",
        "#     #   # event_tuple = temp['EVENT_TYPE'].value_counts()\n",
        "#     #   for i in temp.index:\n",
        "#     #     if data.loc[i, 'EVENT_TYPE'] == event:\n",
        "#     #       # for event, val in event_tuple.items():\n",
        "#     #       tempdata.loc[i, 'COUNT'] = len(temp.index) \n",
        "#     # count+=1\n",
        "#     # print(count)\n",
        "# print(temptotals)\n",
        "\n",
        "# temptotals.to_excel('ACLED_YearwiseTotals.xlsx',index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLocYnVBhHDs"
      },
      "source": [
        "TRAIN-TEST SPLIT ALL REGRESSION MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCXk_pK7jxHs"
      },
      "source": [
        "# def modelize(, X_test, y_train, y_test, models, single): # (singles) argument optional\n",
        "#   # ENCODIZE \n",
        "#   le= LabelEncoder()\n",
        "#   # le = OneHotEncoder(categories='auto')\n",
        "\n",
        "#   le_ = pd.DataFrame()\n",
        "#   le_X_test = pd.DataFrame()\n",
        "#   le_singles = pd.DataFrame()\n",
        "\n",
        "\n",
        "#   for col in .columns:\n",
        "#     if (is_string_dtype([col].dtype)):\n",
        "#       # CAN ALSO USE ONE HOT INSTEAD\n",
        "#       if col == 'LOCATION': # TOO MANY LOCATIONS\n",
        "#         uniques = data2['LOCATION'].unique()\n",
        "#         le.fit(uniques)\n",
        "#         le_[col] = le.transform([col].values.reshape(-1, 1))\n",
        "#         le_X_test[col] = le.transform(X_test[col].values.reshape(-1, 1))\n",
        "#         le_singles[col] = le.transform(singles[col].values.reshape(-1, 1))\n",
        "#       else:\n",
        "#         le_[col] = le.fit_transform([col].values.reshape(-1, 1))\n",
        "#         le_X_test[col] = le.transform(X_test[col].values.reshape(-1, 1))\n",
        "#         le_singles[col] = le.transform(singles[col].values.reshape(-1, 1))\n",
        "#     else:\n",
        "#       # ms.fit([[col]])\n",
        "#       le_[col] = [col].copy()\n",
        "#       le_X_test[col] = X_test[col].copy()\n",
        "#       le_singles[col] = singles[col].copy()\n",
        "\n",
        "#   # print(le_['DISTRICT'])\n",
        "\n",
        "#   count = 0\n",
        "#   for name, model in models:\n",
        "#     # if name == 'Random Forest':\n",
        "\n",
        "#     #   model = RandomForestRegressor()\n",
        "#     regr = model.fit(le_, y_train.values.ravel())\n",
        "#     predictions = regr.predict(le_X_test)\n",
        "    \n",
        "#     count+=1\n",
        "#     # R2 HIGHER BETTER, MSE LOWER BETTER\n",
        "#     print(count,'',name, 'R2 Score: ', round(r2_score(y_test, predictions),3), 'MSE: ', round(mean_squared_error(y_test, predictions, squared= False),3))\n",
        "\n",
        "#     # print('TRUE: ',y_test.values.tolist())\n",
        "#     # print('PREDICTED: ', *predictions)\n",
        "#     # print('\\n')\n",
        "\n",
        "#     # if name == 'Random Forest':\n",
        "#     #   singlesprediction = regr.predict(le_singles)\n",
        "#     #   print('~~~~~~~~~~~~')\n",
        "#     #   print('Single Data: ',singles)\n",
        "#     #   print('Prediction',singlesprediction)\n",
        "#     #   print('~~~~~~~~~~~~')\n",
        "\n",
        "#     # return predictions # for 2020 Predictions\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8hZ_hXX1w8h"
      },
      "source": [
        "# # ALL MODELS train test split\n",
        "\n",
        "# X = data2.loc[:, data2.columns != 'COUNT']\n",
        "# y = data2.loc[:, data2.columns == 'COUNT']\n",
        "\n",
        "# , X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "# models = [('Decision Tree', DecisionTreeRegressor()),\n",
        "#           ('Random Forest', RandomForestRegressor()),\n",
        "#           ('SVR', make_pipeline(StandardScaler(), SVR())),\n",
        "#           ('MLP', make_pipeline(StandardScaler(), MLPRegressor())),\n",
        "#           ('Lasso', linear_model.Lasso()),\n",
        "#           ('Bayesian', linear_model.BayesianRidge()),\n",
        "#           ('Ridge', linear_model.Ridge()),\n",
        "#           ('Linear Regression', LinearRegression())\n",
        "#           ]\n",
        "\n",
        "\n",
        "# # SINGLE DATA PREDICT\n",
        "# single = [[2021,'Protests','Dhaka','DHAKA'],\n",
        "#           [2021,'Riots','Rangpur','RANGPUR']]\n",
        "# singles = pd.DataFrame(single, columns = ['YEAR', 'EVENT_TYPE','LOCATION','DISTRICT'])\n",
        "# modelize(, X_test, y_train, y_test, models,singles)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAFMxh33L47-"
      },
      "source": [
        "3.1 Test and Predict 2020 only for Tableau Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMWzduXDhLVx"
      },
      "source": [
        "PREDICT 2020 ONLY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey2JNv62Prvd"
      },
      "source": [
        "# # 2020 ONLY\n",
        "\n",
        "# train = data2.loc[(data2['YEAR'] != 2020)]\n",
        "# test = data2.loc[(data2['YEAR'] == 2020)]\n",
        "\n",
        "#  = train.loc[:, data2.columns != 'COUNT']\n",
        "# X_test = test.loc[:, data2.columns != 'COUNT']\n",
        "# y_train = train.loc[:, data2.columns == 'COUNT']\n",
        "# y_test = test.loc[:, data2.columns == 'COUNT']\n",
        "\n",
        "# models = [\n",
        "#           # ('MLP', make_pipeline(StandardScaler(), MLPRegressor(random_state=None, max_iter = 100000, learning_rate_init=0.001)))\n",
        "#           ('Random Forest', RandomForestRegressor(max_depth=6, random_state=0))\n",
        "#           ]\n",
        "\n",
        "\n",
        "# # SINGLE DATA PREDICT NOT NEEDED\n",
        "# single = [[2021,'Riots','Bhuapur','TANGAIL'],\n",
        "#           [2021,'ViolenceAgainstCivilians','Chandpur','CHANDPUR']]\n",
        "# singles = pd.DataFrame(single, columns = ['YEAR', 'EVENT_TYPE','LOCATION','DISTRICT'])\n",
        "\n",
        "# y_pred = modelize(, X_test, y_train, y_test, models,singles)\n",
        "\n",
        "# temp_data = test\n",
        "# temp_data.loc[:, 'Predictions'] = y_pred\n",
        "\n",
        "# temp_data.to_excel('ACLED_2020_Prediction_Counts.xlsx',index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVCZr5C70RdW"
      },
      "source": [
        "PREDICT 2021 TOTAL EVENTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qegpJuqu0Xiv"
      },
      "source": [
        "# data3 = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Datasets/ACLED_YearwiseTotals.xlsx')\n",
        "# data3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B51WJKxajfl9"
      },
      "source": [
        "# # # 2021 TOTAL EVENTS\n",
        "\n",
        "# train = data3\n",
        "# test = [[2021]]\n",
        "\n",
        "#  = train.loc[:, data3.columns != 'TOTAL']\n",
        "# y_train = train.loc[:, data3.columns == 'TOTAL']\n",
        "\n",
        "\n",
        "# model = DecisionTreeRegressor()\n",
        "# # model = make_pipeline(StandardScaler(), MLPRegressor(random_state=None, max_iter = 100000, learning_rate_init=0.001))\n",
        "# model.fit(, y_train)\n",
        "# pred = model.predict(test)\n",
        "# print(pred)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsOS_Xn85NX9"
      },
      "source": [
        "PREDICT 2021 SPECIFIC EVENTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "L_xr5N_o5bDA",
        "outputId": "5e8dbbc3-e7f7-4a42-950d-1f829cb0e38f"
      },
      "source": [
        "data2 = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Datasets/ACLED_Data_PrototypeV4.4(locationwise).xlsx')\n",
        "data2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>DISTRICT</th>\n",
              "      <th>COUNT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Ajmiriganj</td>\n",
              "      <td>HABIGANJ</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Akhaura</td>\n",
              "      <td>BRAHMANBARIA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Ashuganj</td>\n",
              "      <td>BRAHMANBARIA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Ashulia</td>\n",
              "      <td>DHAKA</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Baghaichhari</td>\n",
              "      <td>RANGAMATI HILL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11114</th>\n",
              "      <td>2020</td>\n",
              "      <td>ViolenceAgainstCivilians</td>\n",
              "      <td>Telkupi</td>\n",
              "      <td>NAWABGANJ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11115</th>\n",
              "      <td>2020</td>\n",
              "      <td>ViolenceAgainstCivilians</td>\n",
              "      <td>Thakurgaon</td>\n",
              "      <td>THAKURGAON</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11116</th>\n",
              "      <td>2020</td>\n",
              "      <td>ViolenceAgainstCivilians</td>\n",
              "      <td>Thakurpur</td>\n",
              "      <td>CHUADANGA</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11117</th>\n",
              "      <td>2020</td>\n",
              "      <td>ViolenceAgainstCivilians</td>\n",
              "      <td>Tongi</td>\n",
              "      <td>GAZIPUR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11118</th>\n",
              "      <td>2020</td>\n",
              "      <td>ViolenceAgainstCivilians</td>\n",
              "      <td>Ukhiya</td>\n",
              "      <td>COX'S BAZAR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11119 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       YEAR                EVENT_TYPE      LOCATION        DISTRICT  COUNT\n",
              "0      2001                   Battles    Ajmiriganj        HABIGANJ      2\n",
              "1      2001                   Battles       Akhaura    BRAHMANBARIA      1\n",
              "2      2001                   Battles      Ashuganj    BRAHMANBARIA      1\n",
              "3      2001                   Battles       Ashulia           DHAKA      2\n",
              "4      2001                   Battles  Baghaichhari  RANGAMATI HILL      1\n",
              "...     ...                       ...           ...             ...    ...\n",
              "11114  2020  ViolenceAgainstCivilians       Telkupi       NAWABGANJ      1\n",
              "11115  2020  ViolenceAgainstCivilians    Thakurgaon      THAKURGAON      1\n",
              "11116  2020  ViolenceAgainstCivilians     Thakurpur       CHUADANGA      1\n",
              "11117  2020  ViolenceAgainstCivilians         Tongi         GAZIPUR      1\n",
              "11118  2020  ViolenceAgainstCivilians        Ukhiya     COX'S BAZAR      1\n",
              "\n",
              "[11119 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2371
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9szispqS5pLl"
      },
      "source": [
        "# 2021 SPECIFIC EVENTS\n",
        "\n",
        "# CREATE CUSTOM Dataset for 2021 \n",
        "locations = data2['LOCATION'].unique()\n",
        "events = data2['EVENT_TYPE'].unique()\n",
        "\n",
        "# temp_df = pd.DataFrame(columns =['YEAR','EVENT_TYPE','LOCATION','DISTRICT','COUNT'])\n",
        "# count = 0\n",
        "\n",
        "# for location in locations:\n",
        "#   for event in events:\n",
        "#     temp = data2.loc[(data2['LOCATION'] == location) & (data2['EVENT_TYPE'] == event)]\n",
        "#     # temp2 = temp.loc[(temp['EVENT_TYPE'] == event)]\n",
        "#     if len(temp.index) != 0:\n",
        "#       temp_df.loc[count] =  temp.iloc[0]\n",
        "#       count+=1\n",
        "\n",
        "# Using 2020 ROWS ONLY\n",
        "temp_df = data2.loc[(data2['YEAR'] >= 2020)]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUTedswgGRBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd6c324a-7453-4929-efc6-6da74d1fcdc1"
      },
      "source": [
        "print(temp_df)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       YEAR                EVENT_TYPE       LOCATION        DISTRICT  COUNT\n",
            "10595  2020                   Battles       Alokbali       NARSINGDI      1\n",
            "10596  2020                   Battles     Baliadangi      THAKURGAON      1\n",
            "10597  2020                   Battles  Banduk Bhanga  RANGAMATI HILL      1\n",
            "10598  2020                   Battles        Barisal         BARISAL      1\n",
            "10599  2020                   Battles     Bishwanath          SYLHET      1\n",
            "...     ...                       ...            ...             ...    ...\n",
            "11114  2020  ViolenceAgainstCivilians        Telkupi       NAWABGANJ      1\n",
            "11115  2020  ViolenceAgainstCivilians     Thakurgaon      THAKURGAON      1\n",
            "11116  2020  ViolenceAgainstCivilians      Thakurpur       CHUADANGA      1\n",
            "11117  2020  ViolenceAgainstCivilians          Tongi         GAZIPUR      1\n",
            "11118  2020  ViolenceAgainstCivilians         Ukhiya     COX'S BAZAR      1\n",
            "\n",
            "[524 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K64tXqLcGX7q"
      },
      "source": [
        "# DROP COUNT COL\n",
        "temp_df = temp_df.drop(['COUNT'], axis =1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmNwx9-DHhYi",
        "outputId": "3129284d-0200-458c-a98c-8121358c1aa1"
      },
      "source": [
        "# REPLACE ALL YEARS WITH 2021\n",
        "temp_df.loc[temp_df['YEAR'] > 2000, 'YEAR'] = 2021\n",
        "print(temp_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       YEAR                EVENT_TYPE       LOCATION        DISTRICT\n",
            "10595  2021                   Battles       Alokbali       NARSINGDI\n",
            "10596  2021                   Battles     Baliadangi      THAKURGAON\n",
            "10597  2021                   Battles  Banduk Bhanga  RANGAMATI HILL\n",
            "10598  2021                   Battles        Barisal         BARISAL\n",
            "10599  2021                   Battles     Bishwanath          SYLHET\n",
            "...     ...                       ...            ...             ...\n",
            "11114  2021  ViolenceAgainstCivilians        Telkupi       NAWABGANJ\n",
            "11115  2021  ViolenceAgainstCivilians     Thakurgaon      THAKURGAON\n",
            "11116  2021  ViolenceAgainstCivilians      Thakurpur       CHUADANGA\n",
            "11117  2021  ViolenceAgainstCivilians          Tongi         GAZIPUR\n",
            "11118  2021  ViolenceAgainstCivilians         Ukhiya     COX'S BAZAR\n",
            "\n",
            "[524 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUot51gVNkMk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7OlsHBoGOC1",
        "outputId": "4b1649e8-bb20-47aa-c910-4e746016196a"
      },
      "source": [
        "X_train = data2.loc[:, data2.columns != 'COUNT']\n",
        "y_train = data2.loc[:, data2.columns == 'COUNT']\n",
        "X_test = temp_df.loc[:]\n",
        "\n",
        "le= LabelEncoder()\n",
        "\n",
        "le_X_train = pd.DataFrame()\n",
        "le_X_test = pd.DataFrame()\n",
        "\n",
        "for col in X_train.columns:\n",
        "  if (is_string_dtype(X_train[col].dtype)):\n",
        "    if col == 'LOCATION': # TOO MANY LOCATIONS\n",
        "      uniques = data2['LOCATION'].unique()\n",
        "      le.fit(uniques)\n",
        "      le_X_train[col] = le.transform(X_train[col].values.reshape(-1, 1))\n",
        "      le_X_test[col] = le.transform(X_test[col].values.reshape(-1, 1))\n",
        "    else:\n",
        "      le_X_train[col] = le.fit_transform(X_train[col].values.reshape(-1, 1))\n",
        "      le_X_test[col] = le.transform(X_test[col].values.reshape(-1, 1))\n",
        "  else:\n",
        "    # ms.fit(x_train[[col]])\n",
        "    le_X_train[col] = X_train[col].copy()\n",
        "    le_X_test[col] = X_test[col].copy()\n",
        "\n",
        "\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(le_X_train, y_train)\n",
        "y_pred = model.predict(le_X_test)\n",
        "\n",
        "# models = [\n",
        "#           # ('MLP', make_pipeline(StandardScaler(), MLPRegressor(random_state=None, max_iter = 100000, learning_rate_init=0.001)))\n",
        "#           ('Random Forest', RandomForestRegressor(max_depth=6, random_state=0))\n",
        "#           ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# y_pred = modelize(X_train, X_test, y_train, y_test, models,singles)\n",
        "\n",
        "temp_df.loc[:, 'COUNT'] = y_pred\n",
        "print(temp_df)\n",
        "temp_df.to_excel('ACLED_2021_Prediction_Counts(based on 2019 to 2020 columns).xlsx',index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       YEAR                EVENT_TYPE       LOCATION        DISTRICT  COUNT\n",
            "10595  2021                   Battles       Alokbali       NARSINGDI    1.0\n",
            "10596  2021                   Battles     Baliadangi      THAKURGAON    1.0\n",
            "10597  2021                   Battles  Banduk Bhanga  RANGAMATI HILL    1.0\n",
            "10598  2021                   Battles        Barisal         BARISAL    1.0\n",
            "10599  2021                   Battles     Bishwanath          SYLHET    1.0\n",
            "...     ...                       ...            ...             ...    ...\n",
            "11114  2021  ViolenceAgainstCivilians        Telkupi       NAWABGANJ    1.0\n",
            "11115  2021  ViolenceAgainstCivilians     Thakurgaon      THAKURGAON    1.0\n",
            "11116  2021  ViolenceAgainstCivilians      Thakurpur       CHUADANGA    1.0\n",
            "11117  2021  ViolenceAgainstCivilians          Tongi         GAZIPUR    1.0\n",
            "11118  2021  ViolenceAgainstCivilians         Ukhiya     COX'S BAZAR    1.0\n",
            "\n",
            "[524 rows x 5 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAqTFE6lJvUj"
      },
      "source": [
        "Data Analysis Q/A 2021 Q8 and Q9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XLF0HTBJ4M7",
        "outputId": "a5cca399-efac-4fac-f324-9f58e1f0b737"
      },
      "source": [
        "# 8.\t8.\tPredict 2021 Specific Event Totals: \n",
        "for event in events:\n",
        "  temp = temp_df.loc[(temp_df['EVENT_TYPE'] == event)]\n",
        "  count = temp['COUNT'].sum()\n",
        "  print(event, count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Battles 21.0\n",
            "ExplosionsRemoteViolence 7.0\n",
            "Protests 971.0\n",
            "Riots 320.0\n",
            "StrategicDevelopments 17.0\n",
            "ViolenceAgainstCivilians 184.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyKoyZA4bkG0",
        "outputId": "fa0cfed1-b3a0-4662-a539-ca981367f01c"
      },
      "source": [
        "# districts = temp_df['DISTRICT'].unique()\n",
        "\n",
        "# for event in events:\n",
        "#   print(f'~~~~~~~ EVENT: {event} ~~~~~~~~~')\n",
        "#   count_list = []\n",
        "#   for district in districts:\n",
        "#     temp = temp_df.loc[(temp_df['EVENT_TYPE'] == event) &  (temp_df['DISTRICT'] == district)]\n",
        "#     count = temp['COUNT'].sum()\n",
        "#     count_list.append(count)\n",
        "#     print(district,count)\n",
        "#   print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~',max(count_list))\n",
        "#   print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~',min(count_list))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~ EVENT: Battles ~~~~~~~~~\n",
            "NARSINGDI 1.2921618219980755\n",
            "THAKURGAON 1.2543211181291514\n",
            "RANGAMATI HILL 6.552209961847163\n",
            "BARISAL 5.727175134895223\n",
            "SYLHET 5.189702903827646\n",
            "NARAYANGANJ 1.8265675781208213\n",
            "KUSHTIA 1.8748396949174335\n",
            "COX'S BAZAR 1.2155880188761914\n",
            "KHAGRACHARI 1.8402624255905968\n",
            "FARIDPUR 3.270150987264302\n",
            "LALMONIRHAT 1.8604982188079455\n",
            "SIRAJGANJ 1.4058080524214933\n",
            "NAOGAON 1.4840143250515527\n",
            "BANDARBAN 1.2575272122483034\n",
            "CHITTAGONG 0.0\n",
            "DHAKA 0.0\n",
            "BOGRA 0.0\n",
            "BRAHMANBARIA 0.0\n",
            "PANCHAGARH 0.0\n",
            "RANGPUR 0.0\n",
            "BAGERHAT 0.0\n",
            "GAIBANDHA 0.0\n",
            "BARGUNA 0.0\n",
            "NATORE 0.0\n",
            "PATUAKHALI 0.0\n",
            "GAZIPUR 0.0\n",
            "BHOLA 0.0\n",
            "TANGAIL 0.0\n",
            "KURIGRAM 0.0\n",
            "RAJSHAHI 0.0\n",
            "DINAJPUR 0.0\n",
            "CHANDPUR 0.0\n",
            "NAWABGANJ 0.0\n",
            "PABNA 0.0\n",
            "CHUADANGA 0.0\n",
            "HABIGANJ 0.0\n",
            "COMILLA 0.0\n",
            "NILPHAMARI 0.0\n",
            "FENI 0.0\n",
            "MYMENSINGH 0.0\n",
            "GOPALGANJ 0.0\n",
            "JAMALPUR 0.0\n",
            "JESSORE 0.0\n",
            "JHALOKATI 0.0\n",
            "JHENAIDAHA 0.0\n",
            "JOYPURHAT 0.0\n",
            "SATKHIRA 0.0\n",
            "MOULAVIBAZAAR 0.0\n",
            "LAKSHMIPUR 0.0\n",
            "KISHOREGANJ 0.0\n",
            "KHULNA 0.0\n",
            "NARAIL 0.0\n",
            "MADARIPUR 0.0\n",
            "MAGURA 0.0\n",
            "MANIKGANJ 0.0\n",
            "MEHERPUR 0.0\n",
            "NETROKONA 0.0\n",
            "NOAKHALI 0.0\n",
            "PIROJPUR 0.0\n",
            "RAJBARI 0.0\n",
            "SHARIATPUR 0.0\n",
            "MUNSHIGANJ 0.0\n",
            "SUNAMGANJ 0.0\n",
            "SHERPUR 0.0\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 6.552209961847163\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 0.0\n",
            "~~~~~~~ EVENT: ExplosionsRemoteViolence ~~~~~~~~~\n",
            "NARSINGDI 0.0\n",
            "THAKURGAON 0.0\n",
            "RANGAMATI HILL 0.0\n",
            "BARISAL 0.0\n",
            "SYLHET 0.0\n",
            "NARAYANGANJ 0.0\n",
            "KUSHTIA 0.0\n",
            "COX'S BAZAR 0.0\n",
            "KHAGRACHARI 0.0\n",
            "FARIDPUR 0.0\n",
            "LALMONIRHAT 0.0\n",
            "SIRAJGANJ 0.0\n",
            "NAOGAON 1.4723544838652065\n",
            "BANDARBAN 2.623155477200495\n",
            "CHITTAGONG 5.4642902414848855\n",
            "DHAKA 33.49947314369152\n",
            "BOGRA 0.0\n",
            "BRAHMANBARIA 0.0\n",
            "PANCHAGARH 0.0\n",
            "RANGPUR 0.0\n",
            "BAGERHAT 0.0\n",
            "GAIBANDHA 0.0\n",
            "BARGUNA 0.0\n",
            "NATORE 0.0\n",
            "PATUAKHALI 0.0\n",
            "GAZIPUR 0.0\n",
            "BHOLA 0.0\n",
            "TANGAIL 0.0\n",
            "KURIGRAM 0.0\n",
            "RAJSHAHI 0.0\n",
            "DINAJPUR 0.0\n",
            "CHANDPUR 0.0\n",
            "NAWABGANJ 0.0\n",
            "PABNA 0.0\n",
            "CHUADANGA 0.0\n",
            "HABIGANJ 0.0\n",
            "COMILLA 0.0\n",
            "NILPHAMARI 0.0\n",
            "FENI 0.0\n",
            "MYMENSINGH 0.0\n",
            "GOPALGANJ 0.0\n",
            "JAMALPUR 0.0\n",
            "JESSORE 0.0\n",
            "JHALOKATI 0.0\n",
            "JHENAIDAHA 0.0\n",
            "JOYPURHAT 0.0\n",
            "SATKHIRA 0.0\n",
            "MOULAVIBAZAAR 0.0\n",
            "LAKSHMIPUR 0.0\n",
            "KISHOREGANJ 0.0\n",
            "KHULNA 0.0\n",
            "NARAIL 0.0\n",
            "MADARIPUR 0.0\n",
            "MAGURA 0.0\n",
            "MANIKGANJ 0.0\n",
            "MEHERPUR 0.0\n",
            "NETROKONA 0.0\n",
            "NOAKHALI 0.0\n",
            "PIROJPUR 0.0\n",
            "RAJBARI 0.0\n",
            "SHARIATPUR 0.0\n",
            "MUNSHIGANJ 0.0\n",
            "SUNAMGANJ 0.0\n",
            "SHERPUR 0.0\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 33.49947314369152\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 0.0\n",
            "~~~~~~~ EVENT: Protests ~~~~~~~~~\n",
            "NARSINGDI 6.664848550344761\n",
            "THAKURGAON 7.57394694068695\n",
            "RANGAMATI HILL 3.0246842074824882\n",
            "BARISAL 10.879426805030418\n",
            "SYLHET 13.377482955018369\n",
            "NARAYANGANJ 12.166469049726128\n",
            "KUSHTIA 5.133899819467248\n",
            "COX'S BAZAR 1.7878561422560963\n",
            "KHAGRACHARI 4.547066530203312\n",
            "FARIDPUR 5.168376070318006\n",
            "LALMONIRHAT 11.521074452468376\n",
            "SIRAJGANJ 4.354066058609503\n",
            "NAOGAON 2.5525590227499895\n",
            "BANDARBAN 1.7588698531140634\n",
            "CHITTAGONG 28.41320232575708\n",
            "DHAKA 189.30442598119924\n",
            "BOGRA 7.910886130403444\n",
            "BRAHMANBARIA 6.143790833811865\n",
            "PANCHAGARH 3.802727249819587\n",
            "RANGPUR 6.0279338628242485\n",
            "BAGERHAT 3.729022257536494\n",
            "GAIBANDHA 9.146979786524593\n",
            "BARGUNA 4.136043783878613\n",
            "NATORE 3.9052583922733732\n",
            "PATUAKHALI 5.535396450739906\n",
            "GAZIPUR 14.821424397316342\n",
            "BHOLA 7.004647699652036\n",
            "TANGAIL 13.357584423222018\n",
            "KURIGRAM 5.509062017419518\n",
            "RAJSHAHI 21.18517818671667\n",
            "DINAJPUR 16.045968039193973\n",
            "CHANDPUR 3.12800251535112\n",
            "NAWABGANJ 5.55727439293611\n",
            "PABNA 6.899202175879713\n",
            "CHUADANGA 3.797702528922084\n",
            "HABIGANJ 6.862947399530057\n",
            "COMILLA 6.688145701481763\n",
            "NILPHAMARI 7.226173999081618\n",
            "FENI 2.6212460683954855\n",
            "MYMENSINGH 7.700275048245254\n",
            "GOPALGANJ 7.717166133563506\n",
            "JAMALPUR 6.710995769723679\n",
            "JESSORE 7.729154047319166\n",
            "JHALOKATI 2.578083236610305\n",
            "JHENAIDAHA 6.750612067449037\n",
            "JOYPURHAT 7.690638143511688\n",
            "SATKHIRA 6.749257974750622\n",
            "MOULAVIBAZAAR 5.1174078677112735\n",
            "LAKSHMIPUR 5.13345479665367\n",
            "KISHOREGANJ 7.673790103308384\n",
            "KHULNA 9.233320001764623\n",
            "NARAIL 5.105118045499979\n",
            "MADARIPUR 2.5681581881109286\n",
            "MAGURA 2.5681581881109286\n",
            "MANIKGANJ 2.5681581881109286\n",
            "MEHERPUR 2.5681581881109286\n",
            "NETROKONA 2.577661155250861\n",
            "NOAKHALI 2.577661155250861\n",
            "PIROJPUR 1.621975894181182\n",
            "RAJBARI 1.5762182675738763\n",
            "SHARIATPUR 2.488630504585885\n",
            "MUNSHIGANJ 1.5372643908670052\n",
            "SUNAMGANJ 1.9441811019476847\n",
            "SHERPUR 0.0\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 189.30442598119924\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 0.0\n",
            "~~~~~~~ EVENT: Riots ~~~~~~~~~\n",
            "NARSINGDI 6.637876216533963\n",
            "THAKURGAON 2.6505630196553165\n",
            "RANGAMATI HILL 3.0246842074824882\n",
            "BARISAL 10.946233548423598\n",
            "SYLHET 16.468050880179547\n",
            "NARAYANGANJ 16.245891235906086\n",
            "KUSHTIA 6.756346762574957\n",
            "COX'S BAZAR 8.013589345610031\n",
            "KHAGRACHARI 0.0\n",
            "FARIDPUR 9.71005380639552\n",
            "LALMONIRHAT 1.3021852823049482\n",
            "SIRAJGANJ 6.1784761105038655\n",
            "NAOGAON 0.0\n",
            "BANDARBAN 3.037242099804873\n",
            "CHITTAGONG 26.126030687359286\n",
            "DHAKA 153.7247609426198\n",
            "BOGRA 5.144675587981789\n",
            "BRAHMANBARIA 7.594304418194547\n",
            "PANCHAGARH 5.988863421445179\n",
            "RANGPUR 3.459269522226565\n",
            "BAGERHAT 6.319531452437431\n",
            "GAIBANDHA 10.768715934017207\n",
            "BARGUNA 1.3697543848189984\n",
            "NATORE 2.5195564030704376\n",
            "PATUAKHALI 5.734564496403532\n",
            "GAZIPUR 5.619917055705754\n",
            "BHOLA 4.811426273306715\n",
            "TANGAIL 7.771524435975434\n",
            "KURIGRAM 2.5729835870388316\n",
            "RAJSHAHI 22.764167072142243\n",
            "DINAJPUR 6.505136725292359\n",
            "CHANDPUR 5.817820513396778\n",
            "NAWABGANJ 0.0\n",
            "PABNA 13.684283024447234\n",
            "CHUADANGA 0.0\n",
            "HABIGANJ 6.590194844681105\n",
            "COMILLA 21.317452023049853\n",
            "NILPHAMARI 3.4692226550591405\n",
            "FENI 4.162572258724681\n",
            "MYMENSINGH 9.088622959816073\n",
            "GOPALGANJ 15.432529963317052\n",
            "JAMALPUR 3.9926580139024717\n",
            "JESSORE 10.57708248506123\n",
            "JHALOKATI 0.0\n",
            "JHENAIDAHA 15.904671831812914\n",
            "JOYPURHAT 2.578083236610305\n",
            "SATKHIRA 7.303037103606468\n",
            "MOULAVIBAZAAR 2.553839462882079\n",
            "LAKSHMIPUR 2.5609162324284167\n",
            "KISHOREGANJ 5.09275419689174\n",
            "KHULNA 9.365559476319898\n",
            "NARAIL 10.206036574912426\n",
            "MADARIPUR 4.141164707877007\n",
            "MAGURA 0.0\n",
            "MANIKGANJ 2.5351555684313767\n",
            "MEHERPUR 2.5681581881109286\n",
            "NETROKONA 0.0\n",
            "NOAKHALI 4.309083197961879\n",
            "PIROJPUR 3.846997299278316\n",
            "RAJBARI 5.582936319662795\n",
            "SHARIATPUR 1.2687387567274953\n",
            "MUNSHIGANJ 2.8415230522101655\n",
            "SUNAMGANJ 3.8211062110584595\n",
            "SHERPUR 2.488630504585885\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 153.7247609426198\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 0.0\n",
            "~~~~~~~ EVENT: StrategicDevelopments ~~~~~~~~~\n",
            "NARSINGDI 0.0\n",
            "THAKURGAON 0.0\n",
            "RANGAMATI HILL 0.0\n",
            "BARISAL 0.0\n",
            "SYLHET 0.0\n",
            "NARAYANGANJ 0.0\n",
            "KUSHTIA 3.0864809182717394\n",
            "COX'S BAZAR 1.2875245199561827\n",
            "KHAGRACHARI 0.0\n",
            "FARIDPUR 0.0\n",
            "LALMONIRHAT 0.0\n",
            "SIRAJGANJ 2.3687586467786796\n",
            "NAOGAON 0.0\n",
            "BANDARBAN 0.0\n",
            "CHITTAGONG 0.0\n",
            "DHAKA 17.130116200358103\n",
            "BOGRA 0.0\n",
            "BRAHMANBARIA 0.0\n",
            "PANCHAGARH 0.0\n",
            "RANGPUR 0.0\n",
            "BAGERHAT 0.0\n",
            "GAIBANDHA 0.0\n",
            "BARGUNA 0.0\n",
            "NATORE 0.0\n",
            "PATUAKHALI 0.0\n",
            "GAZIPUR 1.5463898197417867\n",
            "BHOLA 0.0\n",
            "TANGAIL 0.0\n",
            "KURIGRAM 0.0\n",
            "RAJSHAHI 0.0\n",
            "DINAJPUR 0.0\n",
            "CHANDPUR 1.3098318059255503\n",
            "NAWABGANJ 0.0\n",
            "PABNA 1.9726214682459067\n",
            "CHUADANGA 0.0\n",
            "HABIGANJ 0.0\n",
            "COMILLA 0.0\n",
            "NILPHAMARI 0.0\n",
            "FENI 0.0\n",
            "MYMENSINGH 0.0\n",
            "GOPALGANJ 0.0\n",
            "JAMALPUR 0.0\n",
            "JESSORE 0.0\n",
            "JHALOKATI 0.0\n",
            "JHENAIDAHA 1.341755828776035\n",
            "JOYPURHAT 0.0\n",
            "SATKHIRA 0.0\n",
            "MOULAVIBAZAAR 0.0\n",
            "LAKSHMIPUR 0.0\n",
            "KISHOREGANJ 0.0\n",
            "KHULNA 0.0\n",
            "NARAIL 0.0\n",
            "MADARIPUR 1.4957750134918733\n",
            "MAGURA 0.0\n",
            "MANIKGANJ 0.0\n",
            "MEHERPUR 0.0\n",
            "NETROKONA 0.0\n",
            "NOAKHALI 0.0\n",
            "PIROJPUR 0.0\n",
            "RAJBARI 0.0\n",
            "SHARIATPUR 0.0\n",
            "MUNSHIGANJ 0.0\n",
            "SUNAMGANJ 0.0\n",
            "SHERPUR 0.0\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 17.130116200358103\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 0.0\n",
            "~~~~~~~ EVENT: ViolenceAgainstCivilians ~~~~~~~~~\n",
            "NARSINGDI 1.5190203699582754\n",
            "THAKURGAON 10.131156493029009\n",
            "RANGAMATI HILL 11.64926004459835\n",
            "BARISAL 8.416540259707746\n",
            "SYLHET 13.499442208218204\n",
            "NARAYANGANJ 4.109211043088607\n",
            "KUSHTIA 4.512409565517053\n",
            "COX'S BAZAR 6.750400919825632\n",
            "KHAGRACHARI 7.587150417507879\n",
            "FARIDPUR 1.542403587646449\n",
            "LALMONIRHAT 7.358310068785991\n",
            "SIRAJGANJ 3.5232783291868595\n",
            "NAOGAON 3.0616979872248202\n",
            "BANDARBAN 6.051565118223213\n",
            "CHITTAGONG 14.162806963945684\n",
            "DHAKA 25.974348220165805\n",
            "BOGRA 5.145006262279875\n",
            "BRAHMANBARIA 1.730600935642739\n",
            "PANCHAGARH 1.5797597794246478\n",
            "RANGPUR 1.1410134238744416\n",
            "BAGERHAT 3.726691793077764\n",
            "GAIBANDHA 0.0\n",
            "BARGUNA 2.87229689818982\n",
            "NATORE 1.4414816325520095\n",
            "PATUAKHALI 1.3449222256333682\n",
            "GAZIPUR 1.3864541033320688\n",
            "BHOLA 0.0\n",
            "TANGAIL 2.4125227591225817\n",
            "KURIGRAM 2.867769989885403\n",
            "RAJSHAHI 9.269657531698257\n",
            "DINAJPUR 5.977338368506086\n",
            "CHANDPUR 4.373710095204864\n",
            "NAWABGANJ 6.265494727026092\n",
            "PABNA 6.313573029227346\n",
            "CHUADANGA 2.86486042935593\n",
            "HABIGANJ 3.035695194612719\n",
            "COMILLA 6.1235530202515145\n",
            "NILPHAMARI 0.0\n",
            "FENI 1.5337059015272883\n",
            "MYMENSINGH 8.58084480211075\n",
            "GOPALGANJ 1.528380760588081\n",
            "JAMALPUR 0.0\n",
            "JESSORE 9.286203585047307\n",
            "JHALOKATI 0.0\n",
            "JHENAIDAHA 4.427522521887772\n",
            "JOYPURHAT 0.0\n",
            "SATKHIRA 2.833835245782845\n",
            "MOULAVIBAZAAR 0.0\n",
            "LAKSHMIPUR 0.0\n",
            "KISHOREGANJ 0.0\n",
            "KHULNA 6.181001455176937\n",
            "NARAIL 4.429223437411678\n",
            "MADARIPUR 1.5338415633003384\n",
            "MAGURA 0.0\n",
            "MANIKGANJ 0.0\n",
            "MEHERPUR 2.9731813053330196\n",
            "NETROKONA 0.0\n",
            "NOAKHALI 2.8727873747416623\n",
            "PIROJPUR 2.6264683777167823\n",
            "RAJBARI 0.0\n",
            "SHARIATPUR 0.0\n",
            "MUNSHIGANJ 1.4884665851732886\n",
            "SUNAMGANJ 1.8063281816798307\n",
            "SHERPUR 0.0\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 25.974348220165805\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpTc5GTgQ96I"
      },
      "source": [
        "# DONT NEED ANYMORE?\n",
        "\n",
        "# le= LabelEncoder()\n",
        "# ms_train_x = pd.DataFrame()\n",
        "# ms_test_x = pd.DataFrame()\n",
        "# # LABEL ENCODER + Min max Scaler\n",
        "# for col in .columns:\n",
        "#   if (is_string_dtype([col].dtype)):\n",
        "#     uniques = [col].unique() # Do this otherwise test doesnt get enough labels to labelencode\n",
        "#     le.fit(uniques)\n",
        "#     ms_train_x[col] = le.transform([[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "#     ms_test_x[col] = le.transform(x_test[[col]]).flatten()\n",
        "#   else:\n",
        "#     # ms.fit([[col]])\n",
        "#     ms_train_x[col] = [col].copy()\n",
        "#     ms_test_x[col] = x_test[col].copy()\n",
        "\n",
        "# regr = MLPRegressor(random_state=1, max_iter=2000).fit(ms_train_x, y_train)\n",
        "# y_pred = regr.predict(ms_test_x)\n",
        "# print(mean_squared_error(y_test, y_pred, squared=False))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW3mnkkvUxjf"
      },
      "source": [
        "# tableau_prototype_2021 = temp_data.loc[(temp_data['YEAR'] == 2020)]\n",
        "# tableau_prototype_2021['PRED_Riots'] = y_pred.astype(int).tolist()\n",
        "# tableau_prototype_2021\n",
        "# tableau_prototype_2021.to_excel('tableau_prototype_predict_totals_riots_2021.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYceVJlWTqcc"
      },
      "source": [
        "K Means Districts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NiYMtgSBTsuh",
        "outputId": "a43951ef-15c9-4b00-a2d8-035c747d712e"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>DISTRICT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Lohagara</td>\n",
              "      <td>23.1998</td>\n",
              "      <td>89.6644</td>\n",
              "      <td>NARAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Hathazari</td>\n",
              "      <td>22.5052</td>\n",
              "      <td>91.8134</td>\n",
              "      <td>CHITTAGONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rangamati</td>\n",
              "      <td>22.6432</td>\n",
              "      <td>92.1919</td>\n",
              "      <td>RANGAMATI HILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajoir</td>\n",
              "      <td>23.1878</td>\n",
              "      <td>90.0322</td>\n",
              "      <td>MADARIPUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajshahi</td>\n",
              "      <td>24.3740</td>\n",
              "      <td>88.6011</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30624</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Paba</td>\n",
              "      <td>24.4417</td>\n",
              "      <td>88.6278</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30625</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bhuapur</td>\n",
              "      <td>24.4604</td>\n",
              "      <td>89.8727</td>\n",
              "      <td>TANGAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30626</th>\n",
              "      <td>2020</td>\n",
              "      <td>Protests</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7406</td>\n",
              "      <td>90.3943</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30627</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bogra</td>\n",
              "      <td>24.8510</td>\n",
              "      <td>89.3711</td>\n",
              "      <td>BOGRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30628</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7333</td>\n",
              "      <td>90.4000</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30629 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       YEAR EVENT_TYPE   LOCATION  LATITUDE  LONGITUDE        DISTRICT\n",
              "0      2001    Battles   Lohagara   23.1998    89.6644          NARAIL\n",
              "1      2001      Riots  Hathazari   22.5052    91.8134      CHITTAGONG\n",
              "2      2001      Riots  Rangamati   22.6432    92.1919  RANGAMATI HILL\n",
              "3      2001      Riots     Rajoir   23.1878    90.0322       MADARIPUR\n",
              "4      2001      Riots   Rajshahi   24.3740    88.6011        RAJSHAHI\n",
              "...     ...        ...        ...       ...        ...             ...\n",
              "30624  2020      Riots       Paba   24.4417    88.6278        RAJSHAHI\n",
              "30625  2020      Riots    Bhuapur   24.4604    89.8727         TANGAIL\n",
              "30626  2020   Protests     Dhaka    23.7406    90.3943           DHAKA\n",
              "30627  2020      Riots      Bogra   24.8510    89.3711           BOGRA\n",
              "30628  2020      Riots     Dhaka    23.7333    90.4000           DHAKA\n",
              "\n",
              "[30629 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qBAvy_cUjFz"
      },
      "source": [
        "# # TRAIN WHOLE DATASET AND CLUSTER\n",
        "\n",
        "# from sklearn.cluster import KMeans\n",
        "# plt.rcParams[\"figure.figsize\"] = (5,5)\n",
        "\n",
        "# train = data[['LONGITUDE', 'LATITUDE']]\n",
        "\n",
        "# km = KMeans(n_clusters=64, init='random')\n",
        "\n",
        "# # GRAPH BEFORE TRAINING\n",
        "# train_plot = pd.DataFrame(train)\n",
        "# train_plot.plot.scatter(x=0, y=1, colormap='jet', title='Before Training')\n",
        "\n",
        "# # TRAIN\n",
        "# km.fit(train)\n",
        "\n",
        "# # PREDICT\n",
        "# prediction = km.predict(train)\n",
        "\n",
        "# # GRAPH AFTER CLUSTERING\n",
        "# train_plot = pd.DataFrame(train)\n",
        "# train_plot['cluster_index'] = pd.Series(prediction)\n",
        "# train_plot.plot.scatter(x=0, y=1, c='cluster_index', colormap='jet', title='After Clustering')\n",
        "\n",
        "# print(len(np.unique(prediction))) # unique clusters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4m8kMI0mzcF"
      },
      "source": [
        "DATA ANALYSIS Q/A:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWBveg-dnb9k"
      },
      "source": [
        "# # data = pd.read_excel('ACLED_Data_Prototype.xlsx')\n",
        "# data = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Datasets/ACLED_Data_PrototypeV2.1.xlsx')\n",
        "# data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X8tXDesniYh"
      },
      "source": [
        "# # # DISTRICTS\n",
        "# data2 = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Datasets/ACLED_Data_PrototypeV4.3(locationwise).xlsx')\n",
        "# data2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqJ-TYvhnZu-"
      },
      "source": [
        "# # 3.\t2001 – 2020 Highest Total Events in which District: \n",
        "# count = data['DISTRICT'].value_counts()\n",
        "# print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGe8SR_YtMuP"
      },
      "source": [
        "# # 5.\t2001 – 2020 Highest Lowest Specific Events in which Districts:\n",
        "# events = data['EVENT_TYPE'].unique()\n",
        "# for event in events:\n",
        "#   temp = data.loc[(data['EVENT_TYPE'] == event)]\n",
        "#   print(f'~~~~~~~ EVENT: {event}')\n",
        "#   count = temp['DISTRICT'].value_counts()\n",
        "#   print(count)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}