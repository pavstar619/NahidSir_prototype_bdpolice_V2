{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NahidSir_ACLED_Prototype.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMCw5/miTrqbpQjnnOns1v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavstar619/NahidSir_prototype_bdpolice_V2/blob/main/NahidSir_ACLED_Prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXrIvym_FUqv"
      },
      "source": [
        "Note: \n",
        "\n",
        "* Acled xlsx event type had some different worded rows. Fixed that after making the first total counts xlsx\n",
        "\n",
        "* (SOLVED) Tried Specific events by separate years with cities. Didnt work out due to each city having unequal amount of events\n",
        "\n",
        "  * (SOLVED) Tried using dictionary but lots of empty arrays as one city might not have any crimes at all for one year. Not sure how to append dict to excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChDHnWza714w",
        "outputId": "2de95dca-735c-44cf-b6dc-3a40541863ea"
      },
      "source": [
        "!pip install XlsxWriter\n",
        "!pip install scikit-multilearn"
      ],
      "execution_count": 807,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: XlsxWriter in /usr/local/lib/python3.7/dist-packages (1.4.3)\n",
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.7/dist-packages (0.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNWsqwkyfoIJ"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import folium\n",
        "\n",
        "from geopy.geocoders import Nominatim, OpenMapQuest\n",
        "from geopy.exc import GeocoderTimedOut\n",
        "\n",
        "\n"
      ],
      "execution_count": 808,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_uDtTnpUAHu"
      },
      "source": [
        "# !pip install geopy\n",
        "# !pip install folium"
      ],
      "execution_count": 809,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z82cj9MeRU1",
        "outputId": "7147a896-203c-443b-8b7d-b63cf8f6a5f9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 810,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM8ZeogDfJas",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "16848a77-5d22-46db-f4b5-5fff07f409b8"
      },
      "source": [
        "# data = pd.read_excel('ACLED_Data_Prototype.xlsx')\n",
        "data = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Datasets/ACLED_Data_PrototypeV2.1.xlsx')\n",
        "data"
      ],
      "execution_count": 811,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>DISTRICT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Lohagara</td>\n",
              "      <td>23.1998</td>\n",
              "      <td>89.6644</td>\n",
              "      <td>NARAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Hathazari</td>\n",
              "      <td>22.5052</td>\n",
              "      <td>91.8134</td>\n",
              "      <td>CHITTAGONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rangamati</td>\n",
              "      <td>22.6432</td>\n",
              "      <td>92.1919</td>\n",
              "      <td>RANGAMATI HILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajoir</td>\n",
              "      <td>23.1878</td>\n",
              "      <td>90.0322</td>\n",
              "      <td>MADARIPUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajshahi</td>\n",
              "      <td>24.3740</td>\n",
              "      <td>88.6011</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30624</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Paba</td>\n",
              "      <td>24.4417</td>\n",
              "      <td>88.6278</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30625</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bhuapur</td>\n",
              "      <td>24.4604</td>\n",
              "      <td>89.8727</td>\n",
              "      <td>TANGAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30626</th>\n",
              "      <td>2020</td>\n",
              "      <td>Protests</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7406</td>\n",
              "      <td>90.3943</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30627</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bogra</td>\n",
              "      <td>24.8510</td>\n",
              "      <td>89.3711</td>\n",
              "      <td>BOGRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30628</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7333</td>\n",
              "      <td>90.4000</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30629 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       YEAR EVENT_TYPE   LOCATION  LATITUDE  LONGITUDE        DISTRICT\n",
              "0      2001    Battles   Lohagara   23.1998    89.6644          NARAIL\n",
              "1      2001      Riots  Hathazari   22.5052    91.8134      CHITTAGONG\n",
              "2      2001      Riots  Rangamati   22.6432    92.1919  RANGAMATI HILL\n",
              "3      2001      Riots     Rajoir   23.1878    90.0322       MADARIPUR\n",
              "4      2001      Riots   Rajshahi   24.3740    88.6011        RAJSHAHI\n",
              "...     ...        ...        ...       ...        ...             ...\n",
              "30624  2020      Riots       Paba   24.4417    88.6278        RAJSHAHI\n",
              "30625  2020      Riots    Bhuapur   24.4604    89.8727         TANGAIL\n",
              "30626  2020   Protests     Dhaka    23.7406    90.3943           DHAKA\n",
              "30627  2020      Riots      Bogra   24.8510    89.3711           BOGRA\n",
              "30628  2020      Riots     Dhaka    23.7333    90.4000           DHAKA\n",
              "\n",
              "[30629 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 811
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn-e-2YfYEiL"
      },
      "source": [
        "# data.loc[0, 'LOCATION']"
      ],
      "execution_count": 812,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUlt8kD-ZR6E"
      },
      "source": [
        "Specific Event types total counts by year\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ9nzSsKhWBY"
      },
      "source": [
        "# years = data.YEAR.unique()\n",
        "# events = data.EVENT_TYPE.unique() # has duplicates same values actual values is 6 not 9\n",
        "# print(events)\n",
        "\n",
        "# totalcount_df = pd.DataFrame(columns = ['YEAR'])\n",
        "\n",
        "# for i in years:\n",
        "#   year = data.loc[data['YEAR'] == i]\n",
        "#   duplicates = year.pivot_table(index = ['EVENT_TYPE'], aggfunc ='size')\n",
        "#   print(i)\n",
        "#   print(duplicates,'\\n')\n",
        "\n",
        "#   totalcount_df = totalcount_df.append(duplicates, ignore_index=True)\n",
        "\n",
        "# totalcount_df\n",
        "\n",
        "# totalcount_df.to_csv('ACLED_totalcounts.csv',index=False)"
      ],
      "execution_count": 813,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3V4dsYFvV1x"
      },
      "source": [
        "Total Events by year and cities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu7R9LnvnhCt"
      },
      "source": [
        "# years = data['YEAR'].unique()\n",
        "# locations = data['LOCATION'].unique()\n",
        "# events = data['EVENT_TYPE'].unique()\n",
        "\n",
        "# locations_totalcount_df = pd.DataFrame(columns = [years])\n",
        "# count = 0\n",
        "\n",
        "# for i in locations:\n",
        "#   for j in years:\n",
        "#     x = data.loc[(data['LOCATION'] == i) & (data['YEAR'] == j)]\n",
        "#     # duplicates = x.pivot_table(index = ['EVENT_TYPE'], aggfunc ='size') # enable this to show specific events like riots murder etc\n",
        "#     sum = x['EVENT_TYPE'].count()\n",
        "#     # print('~~~~~~~~~~~~~~~~~~~~~~')\n",
        "#     # print(i,j,'Total events: ',sum)\n",
        "#     # print(duplicates)\n",
        "\n",
        "#     locations_totalcount_df.loc[count,j] = sum\n",
        "\n",
        "#   count+=1\n",
        "\n",
        "# # locations_totalcount_df\n",
        "\n"
      ],
      "execution_count": 814,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIqKynl0wCHJ"
      },
      "source": [
        "# # Add cities to dataframe\n",
        "# locations_totalcount_df['LOCATION'] = locations.tolist()\n",
        "# locations_totalcount_df"
      ],
      "execution_count": 815,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK8WJE3tu42I"
      },
      "source": [
        "# locations_totalcount_df.to_excel('ACLED_locations_totalcount_df.xlsx',index=False)"
      ],
      "execution_count": 816,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ek_EK1BhN2-"
      },
      "source": [
        "# x = data.loc[(data['LOCATION'] == 'Hathazari') & (data['YEAR'] == 2011)]\n",
        "# x"
      ],
      "execution_count": 817,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2mXTpqfb8GE"
      },
      "source": [
        "Specific Events by years by cities (using Dictionary -> excel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLCofKy-N4pq"
      },
      "source": [
        "# years = data['YEAR'].unique()\n",
        "# locations = data['LOCATION'].unique()\n",
        "# events = data['EVENT_TYPE'].unique()\n",
        "\n",
        "# years_dict = {}\n",
        "# for i in years:\n",
        "#   location_dict = {}\n",
        "#   for j in locations:\n",
        "#     x = data.loc[(data['LOCATION'] == j) & (data['YEAR'] == i)]\n",
        "#     duplicates = x.pivot_table(index = ['EVENT_TYPE'], aggfunc ='size') # enable this to show specific events like riots murder etc\n",
        "#     event_dict = {}\n",
        "#     for event, value in duplicates.items():\n",
        "#       event_dict[event] = value \n",
        "\n",
        "#     location_dict[j] = event_dict\n",
        "\n",
        "#   years_dict[i] = location_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 818,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3OLeI-tPODg"
      },
      "source": [
        "# for i in years_dict:\n",
        "#   print(years_dict[i])"
      ],
      "execution_count": 819,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAI2S5FKSnZv"
      },
      "source": [
        "# writer = pd.ExcelWriter('yearwise_locations_specificevent.xlsx', engine='xlsxwriter')\n",
        "\n",
        "# yearwise_locations_specificevent = pd.DataFrame()\n",
        "# yearwise_locations_specificevent\n",
        "\n",
        "# for year in years_dict:\n",
        "#   count = 0\n",
        "#   for city in years_dict[year]:\n",
        "#     yearwise_locations_specificevent.loc[count, 'LOCATION'] = city\n",
        "\n",
        "#     x = years_dict[year][city]\n",
        "#     for event,value in x.items():\n",
        "#       yearwise_locations_specificevent.loc[count, event] = value\n",
        "#       # yearwise_locations_specificevent[str(event)].iloc[count] = value\n",
        "\n",
        "#     count+=1\n",
        "\n",
        "#     # for event in years_dict[year][city]:\n",
        "\n",
        "\n",
        "#   yearwise_locations_specificevent.to_excel(writer, sheet_name=str(year),index=False)\n",
        "\n",
        "# writer.save()"
      ],
      "execution_count": 820,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmuplMZkj4x0"
      },
      "source": [
        "Specific Events by Event Type by cities (using Dictionary -> excel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxZE0WWFkF70"
      },
      "source": [
        "# years = data['YEAR'].unique()\n",
        "# locations = data['LOCATION'].unique()\n",
        "# events = data['EVENT_TYPE'].unique()\n",
        "\n",
        "# specific_event_type_totalcount = pd.DataFrame()\n",
        "\n",
        "# writer = pd.ExcelWriter('specific_event_type_totalcount.xlsx', engine='xlsxwriter')\n",
        "\n",
        "# for k in events:\n",
        "#   count = 0\n",
        "#   for i in locations:\n",
        "#   # for j in years:\n",
        "#     # x = data.loc[(data['LOCATION'] == i) & (data['YEAR'] == j) & (data['EVENT_TYPE'] == k)]\n",
        "#     x = data.loc[(data['LOCATION'] == i) & (data['EVENT_TYPE'] == k)]\n",
        "#     # duplicates = x.pivot_table(index = ['EVENT_TYPE'], aggfunc ='size') # enable this to show specific events like riots murder etc\n",
        "#     sum = x['EVENT_TYPE'].count()\n",
        "#     # print('~~~~~~~~~~~~~~~~~~~~~~')\n",
        "#     # print(i,j,'Total events: ',sum)\n",
        "#     # print(duplicates)\n",
        "      \n",
        "\n",
        "#     specific_event_type_totalcount.loc[count,'Total'] = sum\n",
        "\n",
        "#     count+=1\n",
        "\n",
        "#   specific_event_type_totalcount.to_excel(writer, sheet_name=str(k),index=False)\n",
        "\n",
        "# writer.save()"
      ],
      "execution_count": 821,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Xzxe8CUd0i"
      },
      "source": [
        "Geo Mapping Stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2UdR40E71LG"
      },
      "source": [
        "1. Geo Map by all locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYqqwRdlUdf-"
      },
      "source": [
        "# plt.figure(figsize = (15,8))\n",
        "# sns.scatterplot(data['LATITUDE'], data['LONGITUDE'])"
      ],
      "execution_count": 822,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChlAL6--WheF"
      },
      "source": [
        "# lat_median = data['LATITUDE'].median() # y\n",
        "# long_median = data['LONGITUDE'].median() # x\n",
        "# print(lat_median,long_median)"
      ],
      "execution_count": 823,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HehUVH2sVhi8"
      },
      "source": [
        "# # create the map.\n",
        "# map_pickup = folium.Map(location=[lat_median, long_median], zoom_start = 6)\n",
        "\n",
        "# # adding the latitude and longitude points to the map.\n",
        "# data.apply(lambda row:folium.Circle(location=[row['LATITUDE'], row['LONGITUDE']], radius = 0.25).add_to(map_pickup), axis=1)\n",
        "\n",
        "# # optional: save the map.\n",
        "# # map_pickup.save('geomap_bd.html')\n",
        "\n",
        "# # display the map: just ask for the object representation in juypter notebook.\n",
        "# map_pickup"
      ],
      "execution_count": 824,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk4jh_Ob0fSJ"
      },
      "source": [
        "Geo Locater find districts and stuff\n",
        "\n",
        "Problems:\n",
        " * Takes too long for each of the 30000 rows (2rows/sec speed)\n",
        " * (Temp Fixed). Use 1380 rows of unique locations instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s83LL7IjvtBp"
      },
      "source": [
        "# # create the locator\n",
        "# geolocator = Nominatim(user_agent=\"GGWP\") # 120 req per min\n",
        "\n",
        "# # getting the location address\n",
        "# location = geolocator.reverse((22.3075,89.0981))\n",
        "# # location = geolocator.geocode('Dhaka')\n",
        "\n",
        "# print(location.raw)\n",
        "# # print(location.raw['address']['state_district'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 825,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "162zpaCzBZNW"
      },
      "source": [
        "\n",
        "# from geopy.geocoders import OpenMapQuest\n",
        "\n",
        "# point = '23.1998, 89.6644' #here's famous Sherlock Holmes' museum lat & lng\n",
        "\n",
        "# geolocator = OpenMapQuest(api_key='x5LPBPjUCj9CUEl4U9fUrnoLGfGv7SWk')\n",
        "# address = geolocator.reverse(point)\n",
        "# print(address[0]) # use other indexes if you want more or less detailed address scope."
      ],
      "execution_count": 826,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUqU8UteBlE0"
      },
      "source": [
        "# # # https://stackoverflow.com/questions/31506272/geopy-too-slow-timeout-all-the-time\n",
        "# # # TIME OUT ERROR FIX\n",
        "\n",
        "# # GEO CODER FUNCTION\n",
        "# def geocode(data,i, recursion=0):\n",
        "#     # print((data.loc[i, 'LATITUDE'], data.loc[i, 'LONGITUDE']))\n",
        "#     try:\n",
        "#         return geolocator.reverse((data.loc[i, 'LATITUDE'], data.loc[i, 'LONGITUDE']))\n",
        "#     except GeocoderTimedOut as e:\n",
        "#         if recursion > 10:      # max recursions\n",
        "#             raise e\n",
        "\n",
        "#         time.sleep(5) # wait a bit\n",
        "#         # try again\n",
        "#         return geocode(i, recursion=recursion + 1)"
      ],
      "execution_count": 827,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ2Ix1Kp3zul"
      },
      "source": [
        "# # GEO LOCATOR FUNCTION\n",
        "# def locator(data,excelname):\n",
        "#   for i in range(len(data)):\n",
        "#     location = geolocator.reverse((data.loc[i, 'LATITUDE'], data.loc[i, 'LONGITUDE']))\n",
        "#     location = geocode(data,i)\n",
        "#     # print(location.raw)\n",
        "#     try:\n",
        "#       # all districts\n",
        "#       if location.raw['address'].__contains__('county'):\n",
        "#         data.loc[i, 'DISTRICT'] = location.raw['address']['county'] # for county key\n",
        "#       elif location.raw['address'].__contains__('state_district'):\n",
        "#         data.loc[i, 'DISTRICT'] = location.raw['address']['state_district'] # for state district key\n",
        "#       elif location.raw['address'].__contains__('city'):\n",
        "#         data.loc[i, 'DISTRICT'] = location.raw['address']['city'] \n",
        "#       else:\n",
        "#         substring = \"জেলা\" # check if substring in state value\n",
        "#         if substring in location.raw['address']['state']:\n",
        "#           data.loc[i, 'DISTRICT'] = location.raw['address']['state'] \n",
        "\n",
        "#       # all divisions\n",
        "#       # data.loc[i, 'DIVISION'] = location.raw['address']['state']\n",
        "#     except KeyError:\n",
        "#       print('not found')\n",
        "#     print(i)\n",
        "\n",
        "#   data.to_excel(excelname,index=False)\n",
        "#   data"
      ],
      "execution_count": 828,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x9ZaT427_gX"
      },
      "source": [
        "2. Geo Map by divisions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL0epL5mI2MO"
      },
      "source": [
        "# x = pd.DataFrame()\n",
        "# x = data.drop_duplicates(['LOCATION'])[['LOCATION','LATITUDE','LONGITUDE']]\n",
        "# x = x.reset_index(drop=True)\n",
        "# x"
      ],
      "execution_count": 829,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48JRijaqEKLI"
      },
      "source": [
        "# locator(x, 'location_by_division.xlsx')"
      ],
      "execution_count": 830,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1aPKvfOOZyg"
      },
      "source": [
        "# RUN FOREVER WITHOUT DISCONNECT \n",
        "# while True:pass"
      ],
      "execution_count": 831,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSqgH3F4sI-o"
      },
      "source": [
        "Classification Note:\n",
        " * Predict using Year,City - Find coords and event type(idk how)\n",
        " * Predict using Year, City - Find only event type (multiple events in one city how to handle?) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf31jjEcd2-N"
      },
      "source": [
        "1. Classify years with events only\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-WXIHVPgpYV"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import linear_model \n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 832,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGqX6QNXd2q_"
      },
      "source": [
        "# data = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Data Outputs/ACLED_event_totalcounts.xlsx')\n",
        "# data"
      ],
      "execution_count": 833,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "552OZvsSfhFC"
      },
      "source": [
        "# def R2_calc(pred_y, test_y): # Closer to 1 better score\n",
        "#   return r2_score(pred_y, test_y)\n",
        "\n",
        "# def MSE_calc(pred_y, test_y): # Lower the better\n",
        "#   return mean_squared_error(pred_y, test_y, squared = False)\n",
        "  \n",
        "# def MAE_calc(pred_y, test_y): # Lower the better\n",
        "#   return mean_absolute_error(pred_y, test_y)\n",
        "\n",
        "# def Error_calc(pred_y, test_y):\n",
        "#   return (pred_y - test_y) / test_y"
      ],
      "execution_count": 834,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4TkXcc0fUJw"
      },
      "source": [
        "# def modelizeall(dmp, dmp_2018):\n",
        "#   # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
        "#   writer = pd.ExcelWriter('ACLED_event_totalcounts_test_pred_data.xlsx', engine='xlsxwriter')\n",
        "#   # writer1 = pd.ExcelWriter('Without2018train_errors_data.xlsx', engine='xlsxwriter')\n",
        "\n",
        "#   model = Sequential()\n",
        "#   model.add(Dense(8, input_dim=1, activation='relu'))\n",
        "#   model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
        "#   model.add(Dense(1, kernel_initializer='normal'))\n",
        "#   # used binary loss function \n",
        "#   model.compile(loss='mse', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "#   # print(model.summary())\n",
        "\n",
        "#   # dmp_x = dmp.loc[:, dmp.columns != 'Robbery']\n",
        "#   # dmp_y = dmp['Robbery']\n",
        "#   for col in dmp.columns[1:].unique():\n",
        "#     print('~~~~~~~~~~~~~~~~~~~~~', col, '~~~~~~~~~~~~~~~~~~~~~')\n",
        "#     dmp_x = dmp['YEAR'].values\n",
        "#     dmp_y = dmp[col].values\n",
        "\n",
        "#     # ASSIGN MANUALLY\n",
        "#     train_x = dmp_x\n",
        "#     train_y = dmp_y\n",
        "\n",
        "#     test_x = dmp_2018['YEAR'].values\n",
        "#     test_y = dmp_2018[col].values\n",
        "\n",
        "\n",
        "#     # train_x, test_x, train_y, test_y = train_test_split(dmp_x, dmp_y, test_size = 0.25, random_state=0)\n",
        "\n",
        "#     # Standard scaling\n",
        "#     ss = StandardScaler()\n",
        "#     ss.fit(train_x.reshape(-1, 1))\n",
        "#     alpha_train_x = ss.transform(train_x.reshape(-1, 1))\n",
        "#     ss_test_x = ss.transform(test_x.reshape(-1, 1))\n",
        "\n",
        "#     # print(train_x)\n",
        "#     # print(test_x)\n",
        "\n",
        "\n",
        "\n",
        "#     # pred for single data\n",
        "#     Xnew = [[2021]]\n",
        "#     # print(len(Xnew[0]))\n",
        "#     # print(len(dmp_x.columns))\n",
        "\n",
        "#     regressor = DecisionTreeRegressor(random_state=0)\n",
        "#     forest = RandomForestRegressor(max_depth=2, random_state=0)\n",
        "#     svr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
        "#     mlp = MLPClassifier(random_state=0, max_iter = 2000)\n",
        "#     lasso = linear_model.Lasso(alpha=0.1)\n",
        "#     bayesian = linear_model.BayesianRidge()\n",
        "#     ridge = linear_model.Ridge()\n",
        "#     lr = LinearRegression()\n",
        "\n",
        "#     regressor.fit(train_x.reshape(-1, 1),train_y)  \n",
        "#     forest.fit(train_x.reshape(-1, 1),train_y) \n",
        "#     svr.fit(train_x.reshape(-1, 1),train_y)\n",
        "#     mlp.fit(alpha_train_x.reshape(-1,1),train_y) \n",
        "#     lasso.fit(train_x.reshape(-1,1),train_y) \n",
        "#     bayesian.fit(train_x.reshape(-1,1),train_y) \n",
        "#     ridge.fit(train_x.reshape(-1,1),train_y) \n",
        "#     lr.fit(train_x.reshape(-1,1),train_y)\n",
        "#     model.fit(train_x,train_y, epochs=30, batch_size=2)\n",
        "\n",
        "\n",
        "\n",
        "#     pred_y = regressor.predict(test_x.reshape(-1, 1))\n",
        "#     pred_y1 = forest.predict(test_x.reshape(-1, 1)) \n",
        "#     pred_y2 = svr.predict(test_x.reshape(-1, 1)) \n",
        "#     pred_y3 = mlp.predict(ss_test_x.reshape(-1, 1))\n",
        "#     pred_y4 = lasso.predict(test_x.reshape(-1,1))\n",
        "#     pred_y5 = bayesian.predict(test_x.reshape(-1,1))\n",
        "#     pred_y6 = ridge.predict(test_x.reshape(-1,1))\n",
        "#     pred_y7 = lr.predict(test_x.reshape(-1,1))\n",
        "#     pred_y8 = model.predict(test_x.reshape(-1,1)).tolist()\n",
        "\n",
        "#     # error_y = (pred_y - test_y) / test_y #lower the better\n",
        "#     # error_y1 = (pred_y1 - test_y) / test_y\n",
        "#     # error_y2 = (pred_y2 - test_y) / test_y\n",
        "#     # error_y3 = (pred_y3 - test_y) / test_y\n",
        "#     # error_y4 = (pred_y4 - test_y) / test_y\n",
        "#     # error_y5 = (pred_y5 - test_y) / test_y\n",
        "#     # error_y6 = (pred_y6 - test_y) / test_y\n",
        "#     # error_y7 = (pred_y7 - test_y) / test_y\n",
        "\n",
        "#     pred_y_list = [pred_y,pred_y1,pred_y2,pred_y3,pred_y4,pred_y5,pred_y6,pred_y7,pred_y8]\n",
        "#     error_y_list = []\n",
        "#     r2_y_list = []\n",
        "#     mse_y_list = []\n",
        "#     mae_y_list = []\n",
        "\n",
        "#     for pred_y in pred_y_list:\n",
        "#       # error_y = Error_calc(pred_y,test_y)\n",
        "#       # error_y_list.append(error_y)\n",
        "\n",
        "#       r2_y = R2_calc(pred_y,test_y)\n",
        "#       r2_y_list.append(r2_y)\n",
        "\n",
        "#       mse_y = MSE_calc(pred_y,test_y)\n",
        "#       mse_y_list.append(mse_y)\n",
        "\n",
        "#       mae_y = MAE_calc(pred_y,test_y)\n",
        "#       mae_y_list.append(mae_y)\n",
        "\n",
        "#     Xpred_y = mlp.predict(Xnew) #one data only\n",
        "\n",
        "#     model_list = ['Decision Tree', 'Random Forest', 'SVR', 'MLP(Adam)', 'Lasso', 'Bayesian', 'Ridge', 'Linear Regression','Neural Net']\n",
        "#     # print('~~~~ Test Val || Predicted Val || Errors: R2, RMSE, MAE ~~~~')\n",
        "#     # for i in range(len(pred_y_list)):\n",
        "#     #   print(model_list[i], 'Test Val: ',test_y, 'Predicted Val: ', pred_y_list[i], 'Errors R2 | RMSE | MAE: ', r2_y_list[i], mse_y_list[i], mae_y_list[i]) # Dont show Metric as only one test row\n",
        "\n",
        "\n",
        "#     # # Put in dataframes\n",
        "#     # errors_data = pd.DataFrame(list(zip(model_list, r2_y_list, mse_y_list, mae_y_list)),\n",
        "#     #            columns =['Algorithms','R2 Score','Mean Square Error(MSE)','Mean Absolute Error(MAE)'])\n",
        "#     # # print(errors_data)\n",
        "#     test_pred_data = pd.DataFrame(columns =['Algorithms','Test Years','Test Values','Predicted Values','R2 Score','Mean Square Error(MSE)','Mean Absolute Error(MAE)'])\n",
        "#     for i in range(len(pred_y_list)):\n",
        "#       test_pred_data.loc[i] = [model_list[i], test_x, test_y, list(np.around(pred_y_list[i],2)), r2_y_list[i], mse_y_list[i], mae_y_list[i]]\n",
        "#     # print(test_pred_data)\n",
        "\n",
        "\n",
        "#     # Put in excel sheets\n",
        "#     # Write each dataframe to a different worksheet.\n",
        "#     test_pred_data.to_excel(writer, sheet_name=col,index=False)\n",
        "#     # errors_data.to_excel(writer1, sheet_name=col,index=False)\n",
        "\n",
        "\n",
        "#     # Xpred_y = mlp.predict(Xnew) #one data only\n",
        "\n",
        "\n",
        "#     # m2_y = mean_squared_error(test_y,pred_y, squared=False)\n",
        "\n",
        "#     # print('~~~~ Test Val || Predicted Val || Errors: R2, RMSE, RSE ~~~~')\n",
        "#     # # print(test_y)\n",
        "#     # print('Test DT: ',test_y,pred_y,error_y) # Decision Tree\n",
        "#     # print('Test RF: ',test_y,pred_y1,error_y1) # Random Forest\n",
        "#     # print('Test SVR: ',test_y,pred_y2,error_y2) # SVM\n",
        "#     # print('Test MLP: ',test_y,pred_y3,error_y3) # mlp\n",
        "#     # print('Test Lasso: ',test_y,pred_y4,error_y4) # lasso\n",
        "#     # print('Test Bayesian: ',test_y,pred_y5,error_y5) # bayesian\n",
        "#     # print('Test Ridge: ',test_y,pred_y6,error_y6) # ridge\n",
        "#     # print('Test Linear Regression: ',test_y,pred_y7,error_y7) # lr\n",
        "\n",
        "#     # print('2018 BEST MLP: ',test_y,pred_y3) # Decision Tree\n",
        "#     print(Xnew,'BEST MLP: ',col,Xpred_y) # Decision Tree\n",
        "\n",
        "\n",
        "#   # Close the Pandas Excel writer and output the Excel file.\n",
        "#   writer.save()\n",
        "#   # writer1.save()"
      ],
      "execution_count": 835,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRZZnCMlfNFr"
      },
      "source": [
        "# # 2018 dmp\n",
        "# dmp_2018 = data.iloc[19:] # 2020\n",
        "# print(dmp_2018)\n",
        "\n",
        "# # 2010 to 2017\n",
        "# dmp_till2017 = data.drop(19)\n",
        "# print(dmp_till2017)\n"
      ],
      "execution_count": 836,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU46Yow0j-WJ"
      },
      "source": [
        "# modelizeall(dmp_till2017, dmp_2018)"
      ],
      "execution_count": 837,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz5xZ01U3DQr"
      },
      "source": [
        "1.1 Predict 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEDWRGeakpHA"
      },
      "source": [
        "# dmp = data\n",
        "# # MODELIZE 2021\n",
        "# for col in data.columns[1:].unique():\n",
        "#   print('~~~~~~~~~~~~~~~~~~~~~', col, '~~~~~~~~~~~~~~~~~~~~~')\n",
        "#   dmp_x = dmp['YEAR'].values\n",
        "#   dmp_y = dmp[col].values\n",
        "\n",
        "#   # ASSIGN MANUALLY\n",
        "#   train_x = dmp_x\n",
        "#   train_y = dmp_y\n",
        "\n",
        "#   # Standard scaling\n",
        "#   ss = StandardScaler()\n",
        "#   ss.fit(train_x.reshape(-1, 1))\n",
        "#   ss_train_x = ss.transform(train_x.reshape(-1, 1))\n",
        "\n",
        "\n",
        "#   # pred for single data\n",
        "#   Xnew = [[2021]]\n",
        "#   # print(len(Xnew[0]))\n",
        "#   # print(len(dmp_x.columns))\n",
        "\n",
        "#   mlp = MLPClassifier(random_state=0, max_iter = 5000)\n",
        "#   mlp.fit(ss_train_x.reshape(-1,1),train_y) \n",
        "\n",
        "#   Xpred_y = mlp.predict(Xnew) #one data only\n",
        "\n",
        "#   print(Xnew,'BEST MLP: ',col,Xpred_y) # Decision Tree\n",
        "\n",
        "\n"
      ],
      "execution_count": 838,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM0KUqN528Xf"
      },
      "source": [
        "2. Multi Label Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD2ZupaKtTIP"
      },
      "source": [
        "Did: \n",
        "* Predicted Event \n",
        "* Predicted Lat,long \n",
        "* Predicted Location\n",
        "\n",
        "Left: \n",
        "* Predict Lat, Long, Event\n",
        "\n",
        "Problem:\n",
        "* Low precisions\n",
        "\n",
        "BREAKTHROUGH:\n",
        "* (FAILED cant read y data) IMPROVED MSE from 0.95 to 0.18 by scaling the y data. R2 from 0.2 to 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXXnaYbjL2Ud"
      },
      "source": [
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": 839,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-nxHHDB3KxR"
      },
      "source": [
        "# data = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /ACLED_Data_Prototype.xlsx')\n",
        "# data"
      ],
      "execution_count": 840,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp5jIDTlp712"
      },
      "source": [
        "2.1 Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa2bghDcTSin"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from pandas.api.types import is_string_dtype\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "\n",
        "# evaluate multioutput regression model with k-fold cross-validation\n",
        "from numpy import absolute\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": 841,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7_hwtDM3rLU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "dd49fa7f-7f8b-40c8-b9e3-06560644508f"
      },
      "source": [
        "# x = data.copy()\n",
        "# x = x.drop('YEAR',axis=1)\n",
        "# x"
      ],
      "execution_count": 842,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>DISTRICT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Battles</td>\n",
              "      <td>Lohagara</td>\n",
              "      <td>23.1998</td>\n",
              "      <td>89.6644</td>\n",
              "      <td>NARAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riots</td>\n",
              "      <td>Hathazari</td>\n",
              "      <td>22.5052</td>\n",
              "      <td>91.8134</td>\n",
              "      <td>CHITTAGONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Riots</td>\n",
              "      <td>Rangamati</td>\n",
              "      <td>22.6432</td>\n",
              "      <td>92.1919</td>\n",
              "      <td>RANGAMATI HILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajoir</td>\n",
              "      <td>23.1878</td>\n",
              "      <td>90.0322</td>\n",
              "      <td>MADARIPUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajshahi</td>\n",
              "      <td>24.3740</td>\n",
              "      <td>88.6011</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30624</th>\n",
              "      <td>Riots</td>\n",
              "      <td>Paba</td>\n",
              "      <td>24.4417</td>\n",
              "      <td>88.6278</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30625</th>\n",
              "      <td>Riots</td>\n",
              "      <td>Bhuapur</td>\n",
              "      <td>24.4604</td>\n",
              "      <td>89.8727</td>\n",
              "      <td>TANGAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30626</th>\n",
              "      <td>Protests</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7406</td>\n",
              "      <td>90.3943</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30627</th>\n",
              "      <td>Riots</td>\n",
              "      <td>Bogra</td>\n",
              "      <td>24.8510</td>\n",
              "      <td>89.3711</td>\n",
              "      <td>BOGRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30628</th>\n",
              "      <td>Riots</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7333</td>\n",
              "      <td>90.4000</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30629 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      EVENT_TYPE   LOCATION  LATITUDE  LONGITUDE        DISTRICT\n",
              "0        Battles   Lohagara   23.1998    89.6644          NARAIL\n",
              "1          Riots  Hathazari   22.5052    91.8134      CHITTAGONG\n",
              "2          Riots  Rangamati   22.6432    92.1919  RANGAMATI HILL\n",
              "3          Riots     Rajoir   23.1878    90.0322       MADARIPUR\n",
              "4          Riots   Rajshahi   24.3740    88.6011        RAJSHAHI\n",
              "...          ...        ...       ...        ...             ...\n",
              "30624      Riots       Paba   24.4417    88.6278        RAJSHAHI\n",
              "30625      Riots    Bhuapur   24.4604    89.8727         TANGAIL\n",
              "30626   Protests     Dhaka    23.7406    90.3943           DHAKA\n",
              "30627      Riots      Bogra   24.8510    89.3711           BOGRA\n",
              "30628      Riots     Dhaka    23.7333    90.4000           DHAKA\n",
              "\n",
              "[30629 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 842
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_crY-gUTL6LN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0167463-5a76-4fb6-aa2a-52425d3b91b3"
      },
      "source": [
        "# x = data[['YEAR','LOCATION']]\n",
        "# # x = data[['YEAR','LOCATION','LATITUDE','LONGITUDE']]\n",
        "# # x = x.drop('EVENT_TYPE', axis = 1)\n",
        "# y = data[['LATITUDE','LONGITUDE','EVENT_TYPE']]\n",
        "# # y = data[['EVENT_TYPE']]\n",
        "\n",
        "# # x = data.loc[:, data.columns != ('EVENT_TYPE',)]\n",
        "# # y = data.loc[:, data.columns == 'EVENT_TYPE']\n",
        "\n",
        "# print(x)\n",
        "# print(y)"
      ],
      "execution_count": 843,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       YEAR   LOCATION\n",
            "0      2001   Lohagara\n",
            "1      2001  Hathazari\n",
            "2      2001  Rangamati\n",
            "3      2001     Rajoir\n",
            "4      2001   Rajshahi\n",
            "...     ...        ...\n",
            "30624  2020       Paba\n",
            "30625  2020    Bhuapur\n",
            "30626  2020     Dhaka \n",
            "30627  2020      Bogra\n",
            "30628  2020     Dhaka \n",
            "\n",
            "[30629 rows x 2 columns]\n",
            "       LATITUDE  LONGITUDE EVENT_TYPE\n",
            "0       23.1998    89.6644    Battles\n",
            "1       22.5052    91.8134      Riots\n",
            "2       22.6432    92.1919      Riots\n",
            "3       23.1878    90.0322      Riots\n",
            "4       24.3740    88.6011      Riots\n",
            "...         ...        ...        ...\n",
            "30624   24.4417    88.6278      Riots\n",
            "30625   24.4604    89.8727      Riots\n",
            "30626   23.7406    90.3943   Protests\n",
            "30627   24.8510    89.3711      Riots\n",
            "30628   23.7333    90.4000      Riots\n",
            "\n",
            "[30629 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxjVoeVW-hQW"
      },
      "source": [
        "# # USE THIS OTHERWISE LE.FIT CAUSES PROBLEMS\n",
        "# unique_events = data['EVENT_TYPE'].unique()\n",
        "# unique_locations = data['LOCATION'].unique()"
      ],
      "execution_count": 844,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca56odIXlnqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b92114f0-9b86-4b85-b735-7c52e94a03e6"
      },
      "source": [
        "# # x_numpy = x.to_numpy()\n",
        "# # y_numpy = y.to_numpy()\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
        "# # stratify=y_numpy\n",
        "\n",
        "# y1_train = y_train[['LATITUDE','LONGITUDE']]\n",
        "# y2_train = y_train[['EVENT_TYPE']]\n",
        "\n",
        "# y1_test = y_test[['LATITUDE','LONGITUDE']]\n",
        "# y2_test = y_test[['EVENT_TYPE']]\n",
        "\n",
        "\n",
        "# # MULTI OUTPUT REGRESSION MODELS: LinearRegression, KNeighborsRegressor, DecisionTreeRegressor,RandomForestRegressor\n",
        "\n",
        "# # clf_models = [\n",
        "# #           ('MLP', make_pipeline(StandardScaler(), MLPClassifier())),\n",
        "# #           # ('Linear Regression', LinearRegression()),\n",
        "# #           ('Random Forest', RandomForestClassifier()),\n",
        "# #           # ('Decision Tree', DecisionTreeClassifier()),\n",
        "# #           ('SVM', make_pipeline(StandardScaler(), SVC())),\n",
        "# #           ('KNN', make_pipeline(StandardScaler(), KNeighborsClassifier())),\n",
        "# #           # ('Naive Bayes',GaussianNB()),\n",
        "# #           # ('Logistics Regression', LogisticRegression()),\n",
        "# #           # ('Stochastic Gradient Descent', SGDClassifier()),\n",
        "# #           # ('LightGBM', LGBMClassifier()),\n",
        "# #           # ('AdaBoost', AdaBoostClassifier()),\n",
        "# #           # ('XGBoost', XGBClassifier())\n",
        "# #           ]\n",
        "\n",
        "# models = [\n",
        "#                ('MLP', make_pipeline(StandardScaler(), MLPRegressor()), make_pipeline(StandardScaler(), MLPClassifier())),\n",
        "#                ('Random Forest', RandomForestRegressor(), RandomForestClassifier()),\n",
        "#                ('SVM', MultiOutputRegressor(make_pipeline(StandardScaler(), SVR())), make_pipeline(StandardScaler(), SVC())),\n",
        "#                ('KNN', make_pipeline(StandardScaler(), KNeighborsRegressor()), make_pipeline(StandardScaler(), KNeighborsClassifier()))\n",
        "#                ]\n",
        "\n",
        "# # single  = [2021, 15, 24, 89]\n",
        "\n",
        "# # ms = MinMaxScaler()\n",
        "# # ms = StandardScaler()\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# # le.fit(train_y)\n",
        "# # train_y = le.transform(train_y)\n",
        "# # test_y = le.transform(test_y)\n",
        "\n",
        "# ms_train_x = pd.DataFrame()\n",
        "# ms_test_x = pd.DataFrame()\n",
        "\n",
        "# # LABEL ENCODER + Min max Scaler\n",
        "# for col in x_train.columns:\n",
        "#   if (is_string_dtype(x_train[col].dtype)):\n",
        "#     uniques = data[col].unique() # Do this otherwise test doesnt get enough labels to labelencode\n",
        "#     le.fit(uniques)\n",
        "#     ms_train_x[col] = le.transform(x_train[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "#     ms_test_x[col] = le.transform(x_test[[col]]).flatten()\n",
        "\n",
        "#   else:\n",
        "#     ms.fit(x_train[[col]])\n",
        "#     ms_train_x[col] = x_train[col].copy() # flatten otherwise 1d doesnt work as numpy array\n",
        "#     ms_test_x[col] = x_test[col].copy()\n",
        "\n",
        "# # print(ms_train_x)\n",
        "# # print(ms_test_x)\n",
        "\n",
        "# # y2 test encode:\n",
        "# le.fit(y2_train)\n",
        "# le_y2_train = le.transform(y2_train)\n",
        "# le_y2_test = le.transform(y2_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ useless code # all to use\n",
        "# # # PREPROCESS LOCATION\n",
        "# # le = LabelEncoder()\n",
        "\n",
        "# # le.fit(unique_events)\n",
        "# # x_train[:,1] = le.transform(x_train[:,1]) # Events\n",
        "# # x_test[:,1] = le.transform(x_test[:,1])\n",
        "# # print(le.classes_)\n",
        "\n",
        "\n",
        "# # le.fit(unique_locations)\n",
        "# # x_train[:,2] = le.transform(x_train[:,2]) # Locations\n",
        "# # x_test[:,2] = le.transform(x_test[:,2])\n",
        "# # print(le.classes_)\n",
        "# # # x_train.loc[:, ('LOCATION')] = le.transform(x_train.loc[:, ('LOCATION')]) # IMPORTANT: USE .loc instead of direct ['LOCATION'] otherwise chain indexing error\n",
        "# # # x_test.loc[:, ('LOCATION')] = le.transform(x_test.loc[:, ('LOCATION')])\n",
        "# # # print(x['LOCATION'])\n",
        "# # # single[1] = le.transform(single[1])\n",
        "\n",
        "\n",
        "# # # df = pd.DataFrame(single)\n",
        "# # # df.loc[1] = le.transform(df.loc[1].values)\n",
        "# # # single = df.values.tolist()\n",
        "\n",
        "\n",
        "# # # PREPROCESS Y LABELS\n",
        "# # # le2 = LabelEncoder()\n",
        "# # # le2.fit(unique_events)\n",
        "# # # y_train = le2.transform(y_train)\n",
        "# # # y_test = le2.transform(y_test)\n",
        "# # # print(le2.classes_)\n",
        "\n",
        "# # # STANDARD SCALE X Attributes\n",
        "# # ss = StandardScaler()\n",
        "# # ss.fit(x_train)\n",
        "# # x_train = ss.transform(x_train)\n",
        "# # x_test = ss.transform(x_test)\n",
        "# # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ useless code\n",
        "\n",
        "\n",
        "\n",
        "# # df = ss.transform(df)\n",
        "# # single = df.values.tolist()\n",
        "\n",
        "\n",
        "# for name, model1, model2 in models:\n",
        "#   regr = model1.fit(ms_train_x, y1_train)\n",
        "#   clf = model2.fit(ms_train_x, le_y2_train)\n",
        "\n",
        "#   predictions1 = regr.predict(ms_test_x)\n",
        "#   predictions2 = clf.predict(ms_test_x)\n",
        "\n",
        "#   # single_pred = clf.predict([single])\n",
        "\n",
        "#   print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "#   print(name)\n",
        "#   # print(single_pred)\n",
        "#   # print(predictions)\n",
        "#   print('R2 Score: ', r2_score(y1_test, predictions1), 'MSE: ', mean_squared_error(y1_test, predictions1, squared= False))\n",
        "\n",
        "#   print('Precision | Recall | F1 Score | Support')\n",
        "#   print(precision_recall_fscore_support(le_y2_test, predictions2, average='weighted', labels=np.unique(predictions2))) # why did i use np.unique()??\n",
        "#   # print(classification_report(y_test,predictions, target_names=(le.classes_).tolist()))\n",
        "#   # print(classification_report(y_test,predictions, target_names=(le.classes_).tolist()))\n",
        "\n"
      ],
      "execution_count": 845,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "MLP\n",
            "R2 Score:  0.07321786608969866 MSE:  0.9336620645940993\n",
            "Precision | Recall | F1 Score | Support\n",
            "(0.5167910102678748, 0.7101427498121713, 0.5878245442578682, None)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Random Forest\n",
            "R2 Score:  0.9313865833746922 MSE:  0.25401778929080193\n",
            "Precision | Recall | F1 Score | Support\n",
            "(0.4855091680146444, 0.5152900206768963, 0.4950207062093669, None)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "SVM\n",
            "R2 Score:  0.05114797811223376 MSE:  0.9460080373062455\n",
            "Precision | Recall | F1 Score | Support\n",
            "(0.5024196549080336, 0.6856498873027799, 0.5572470721406719, None)\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "KNN\n",
            "R2 Score:  0.543366763162541 MSE:  0.6536037626764631\n",
            "Precision | Recall | F1 Score | Support\n",
            "(0.4477105444134915, 0.4778539558167374, 0.45374421488152084, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqu3LVzEp071"
      },
      "source": [
        "2.2 Whole data as input: Did regr and clf separate predictions same input\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtbSFFzlqiq6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "6b95f0e4-2add-4338-d50d-2cd16ec425cd"
      },
      "source": [
        "# data"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>DISTRICT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Lohagara</td>\n",
              "      <td>23.1998</td>\n",
              "      <td>89.6644</td>\n",
              "      <td>NARAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Hathazari</td>\n",
              "      <td>22.5052</td>\n",
              "      <td>91.8134</td>\n",
              "      <td>CHITTAGONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rangamati</td>\n",
              "      <td>22.6432</td>\n",
              "      <td>92.1919</td>\n",
              "      <td>RANGAMATI HILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajoir</td>\n",
              "      <td>23.1878</td>\n",
              "      <td>90.0322</td>\n",
              "      <td>MADARIPUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajshahi</td>\n",
              "      <td>24.3740</td>\n",
              "      <td>88.6011</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30624</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Paba</td>\n",
              "      <td>24.4417</td>\n",
              "      <td>88.6278</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30625</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bhuapur</td>\n",
              "      <td>24.4604</td>\n",
              "      <td>89.8727</td>\n",
              "      <td>TANGAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30626</th>\n",
              "      <td>2020</td>\n",
              "      <td>Protests</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7406</td>\n",
              "      <td>90.3943</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30627</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bogra</td>\n",
              "      <td>24.8510</td>\n",
              "      <td>89.3711</td>\n",
              "      <td>BOGRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30628</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7333</td>\n",
              "      <td>90.4000</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30629 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       YEAR EVENT_TYPE   LOCATION  LATITUDE  LONGITUDE        DISTRICT\n",
              "0      2001    Battles   Lohagara   23.1998    89.6644          NARAIL\n",
              "1      2001      Riots  Hathazari   22.5052    91.8134      CHITTAGONG\n",
              "2      2001      Riots  Rangamati   22.6432    92.1919  RANGAMATI HILL\n",
              "3      2001      Riots     Rajoir   23.1878    90.0322       MADARIPUR\n",
              "4      2001      Riots   Rajshahi   24.3740    88.6011        RAJSHAHI\n",
              "...     ...        ...        ...       ...        ...             ...\n",
              "30624  2020      Riots       Paba   24.4417    88.6278        RAJSHAHI\n",
              "30625  2020      Riots    Bhuapur   24.4604    89.8727         TANGAIL\n",
              "30626  2020   Protests     Dhaka    23.7406    90.3943           DHAKA\n",
              "30627  2020      Riots      Bogra   24.8510    89.3711           BOGRA\n",
              "30628  2020      Riots     Dhaka    23.7333    90.4000           DHAKA\n",
              "\n",
              "[30629 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XegsC3asehVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a581e10-8279-4d36-c2be-daa5e1c0e3b6"
      },
      "source": [
        "# x = data[['YEAR','LOCATION']]\n",
        "# y1 = data[['LATITUDE','LONGITUDE']]\n",
        "# y2 = data[['EVENT_TYPE']]\n",
        "# print(x)\n",
        "# print(y1)\n",
        "# print(y2)"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       YEAR   LOCATION\n",
            "0      2001   Lohagara\n",
            "1      2001  Hathazari\n",
            "2      2001  Rangamati\n",
            "3      2001     Rajoir\n",
            "4      2001   Rajshahi\n",
            "...     ...        ...\n",
            "30624  2020       Paba\n",
            "30625  2020    Bhuapur\n",
            "30626  2020     Dhaka \n",
            "30627  2020      Bogra\n",
            "30628  2020     Dhaka \n",
            "\n",
            "[30629 rows x 2 columns]\n",
            "       LATITUDE  LONGITUDE\n",
            "0       23.1998    89.6644\n",
            "1       22.5052    91.8134\n",
            "2       22.6432    92.1919\n",
            "3       23.1878    90.0322\n",
            "4       24.3740    88.6011\n",
            "...         ...        ...\n",
            "30624   24.4417    88.6278\n",
            "30625   24.4604    89.8727\n",
            "30626   23.7406    90.3943\n",
            "30627   24.8510    89.3711\n",
            "30628   23.7333    90.4000\n",
            "\n",
            "[30629 rows x 2 columns]\n",
            "      EVENT_TYPE\n",
            "0        Battles\n",
            "1          Riots\n",
            "2          Riots\n",
            "3          Riots\n",
            "4          Riots\n",
            "...          ...\n",
            "30624      Riots\n",
            "30625      Riots\n",
            "30626   Protests\n",
            "30627      Riots\n",
            "30628      Riots\n",
            "\n",
            "[30629 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWtsxxTJrHZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a34a9c-ce13-4ef8-8611-7d2476206db6"
      },
      "source": [
        "# # model_regr = make_pipeline(StandardScaler(), RandomForestRegressor())\n",
        "# # model_clf = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
        "# model_regr = RandomForestRegressor()\n",
        "# model_clf = RandomForestClassifier()\n",
        "\n",
        "# ms_train_x = pd.DataFrame()\n",
        "\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# # # LABEL ENCODER + Min max Scaler ~~ Training Data ~~ \n",
        "# for col in x.columns:\n",
        "#   if (is_string_dtype(x[col].dtype)):\n",
        "#     uniques = data[col].unique() # Do this otherwise test doesnt get enough labels to labelencode\n",
        "#     le.fit(uniques)\n",
        "#     ms_train_x[col] = le.transform(x[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "#   else:\n",
        "#     ms_train_x[col] = x[col].copy() # flatten otherwise 1d doesnt work as numpy array\n",
        "#     # ms.fit(x[[col]])\n",
        "#     # ms_train_x[col] = ms.transform(x[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "\n",
        "# Xnew = [[2021, 'Dhaka'],[2021,'Barisal']]\n",
        "# df_Xnew = pd.DataFrame(Xnew, columns = ['YEAR', 'LOCATION'])\n",
        "\n",
        "# ms_df_Xnew = pd.DataFrame()\n",
        "\n",
        "# # # LABEL ENCODER + Min max Scaler ~~ Single Datas ~~\n",
        "# for col in df_Xnew.columns:\n",
        "#   if (is_string_dtype(df_Xnew[col].dtype)):\n",
        "#     ms_df_Xnew[col] = le.transform(df_Xnew[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "#   else:\n",
        "#     ms_df_Xnew[col] = df_Xnew[col].copy() # flatten otherwise 1d doesnt work as numpy array\n",
        "#     # ms_df_Xnew[col] = ms.transform(df_Xnew[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "\n",
        "# # Label Encoder Test Data \n",
        "# uniques = y2['EVENT_TYPE'].unique()\n",
        "# le.fit(uniques)\n",
        "# le_y2 = le.transform(y2['EVENT_TYPE'])\n",
        "# # Xnew[1] = le.transform(Xnew[1])\n",
        "# # print(le_y2)\n",
        "\n",
        "# # print(ms_train_x)\n",
        "# # print(y1)\n",
        "# # print(y2)\n",
        "\n",
        "# model_regr.fit(ms_train_x, y1)\n",
        "# model_clf.fit(ms_train_x,y2)\n",
        "\n",
        "# pred_regr = model_regr.predict(ms_df_Xnew)\n",
        "# pred_clf = model_clf.predict_proba(ms_df_Xnew)\n",
        "\n",
        "# print('~~ Probability Classes ~~ : ', model_clf.classes_)\n",
        "\n",
        "# for i in range(len(pred_regr)):\n",
        "#   print('Test Data: ',Xnew[i])\n",
        "#   print('Predicted Data: ',pred_regr[i],pred_clf[i])\n"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "~~ Probability Classes ~~ :  ['Battles' 'ExplosionsRemoteViolence' 'Protests' 'Riots'\n",
            " 'StrategicDevelopments' 'ViolenceAgainstCivilians']\n",
            "Test Data:  [2021, 'Dhaka']\n",
            "Predicted Data:  [23.7104 90.4074] [0.         0.00568298 0.79119182 0.13058522 0.02704326 0.04549672]\n",
            "Test Data:  [2021, 'Barisal']\n",
            "Predicted Data:  [22.705  90.3701] [0.04311225 0.         0.77633601 0.10693892 0.         0.07361282]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr5L05wkZ7ip"
      },
      "source": [
        "** DONT NEED THIS SECTION ANYMORE\n",
        "\n",
        "Problem:\n",
        " * Only 5 labels shown but should be 6 events\n",
        "\n",
        "Ideas:\n",
        "* try adding more col in train y\n",
        "* do the 3 col preds separtely or coord at once then append result\n",
        "* do the lat long first. Add to dataset then do the event type\n",
        "\n",
        "Solve: \n",
        "* 2 ways to solve this https://machinelearningmastery.com/multi-output-regression-models-with-python/. Another problem arises since event type is classification and location is regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdXNrp24bONZ"
      },
      "source": [
        "# x = data.loc[:, data.columns != 'EVENT_TYPE']\n",
        "# y = data['EVENT_TYPE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fou5Oiq0Nvey"
      },
      "source": [
        "# data['EVENT_TYPE'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QskWuIlJM20w"
      },
      "source": [
        "# # x, y = make_multilabel_classification(n_samples = len(data['EVENT_TYPE'].unique()), random_state=0,return_indicator=False)\n",
        "# # this will generate a random multi-label dataset\n",
        "# x, y = make_multilabel_classification(sparse = True, n_labels = 6, return_indicator = 'sparse', allow_unlabeled = False)\n",
        "# # print(x)\n",
        "# # print(y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awc95A1YPT_J"
      },
      "source": [
        "# # using binary relevance\n",
        "# from skmultilearn.problem_transform import BinaryRelevance\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# # initialize binary relevance multi-label classifier\n",
        "# # with a gaussian naive bayes base classifier\n",
        "# classifier = BinaryRelevance(GaussianNB())\n",
        "\n",
        "# # train\n",
        "# classifier.fit(x_train, y_train)\n",
        "\n",
        "# # predict\n",
        "# predictions = classifier.predict(x_test)\n",
        "# print(predictions.toarray())\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# print(classification_report(y_test.toarray(),predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QHwkYjcRZ84"
      },
      "source": [
        "3. Predict Total Events by district"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cik51HxdRmJB"
      },
      "source": [
        "Instructions:\n",
        "1. Join Districts\n",
        "2. Drop Rows of West Bengal\n",
        "3. Input Year, District, Event Type. Output Lat,long, Total Count Specific Event"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbqKu4EFRZw5"
      },
      "source": [
        "# # DISTRICTS\n",
        "# data2 = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Data Outputs/ACLED_location_by_district_V2.xlsx')\n",
        "# data2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEWcmq41zCM3"
      },
      "source": [
        "Join Districts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1Os_MwQS0Jb"
      },
      "source": [
        "# # 1. JOIN DISTRICTS\n",
        "\n",
        "# # count = 0\n",
        "# # for i in range(len(data.index)):\n",
        "# #   for j in range(len(data2.index)):\n",
        "# #     if(data['LOCATION'][i] == data2['LOCATION'][j]):\n",
        "# #       data.loc[i, 'DISTRICT'] = data2['CAPITALIZED'][j]\n",
        "# #   count+=1\n",
        "# #   print(count)\n",
        "\n",
        "# tempdata = data\n",
        "\n",
        "# count = 0\n",
        "# locations = data2['LOCATION'].unique()\n",
        "\n",
        "# for location in locations:\n",
        "#   temp = data.loc[(data['LOCATION'] == location)]\n",
        "#   for i in temp.index:\n",
        "#     for j in range(len(data2.index)):\n",
        "#       if data2.loc[j, 'LOCATION'] == location:\n",
        "#         tempdata.loc[i, 'DISTRICT'] = data2.loc[j,'CAPITALIZED']\n",
        "    \n",
        "#     count+=1\n",
        "#     print(count)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUidgeeoc-Sq"
      },
      "source": [
        "# # CHECK IF ANY NULL VAL\n",
        "# tempdata.isnull().values.any()\n",
        "\n",
        "# is_NaN = tempdata.isnull()\n",
        "# row_has_NaN = is_NaN.any(axis=1)\n",
        "# rows_with_NaN = tempdata[row_has_NaN]\n",
        "# for i in rows_with_NaN['LOCATION']:\n",
        "#   print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iZRrpMK9g8K"
      },
      "source": [
        "# for i in rows_with_NaN.index:\n",
        "#   if rows_with_NaN.loc[i, 'LOCATION'] == 'Dhaka':\n",
        "#     tempdata.loc[i,'DISTRICT'] == 'DHAKA'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MggROCBTcm13"
      },
      "source": [
        "# # # # ADD DHAKA AS MISSING VAL\n",
        "# tempdata.fillna(value = 'DHAKA', inplace = True)\n",
        "# # # tempdata.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC-XkAIr_6fB"
      },
      "source": [
        "# tempdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY1-v5NXy8-k"
      },
      "source": [
        "# tempdata.to_excel('ACLED_Data_PrototypeV2.1.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI9V-DXCy9ad"
      },
      "source": [
        "Dataset generator for specific event counts\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ARn8xSRgJIQ"
      },
      "source": [
        "# # Dataset Generator for Specific Event Counts\n",
        "# # ADD TOTALS OF each specific events per year for each col\n",
        "# # BETTER OPTIONS use later: slice thru range of year indexes in temp. Might be faster to iter. Single rows take too long to iter (DONE)\n",
        "\n",
        "# tempdata = data\n",
        "# tempdata.drop(['LONGITUDE','LATITUDE'], axis = 1)\n",
        "\n",
        "# years = data['YEAR'].unique()\n",
        "# events = data['EVENT_TYPE'].unique()\n",
        "# # districts = data['DISTRICT'].unique()\n",
        "# locations = data['LOCATION'].unique()\n",
        "\n",
        "# count = 0\n",
        "# for year in years:\n",
        "#   for location in locations:\n",
        "#     for event in events:\n",
        "#       temp = data.loc[(data['YEAR'] == year) & (data['LOCATION'] == location) & (data['EVENT_TYPE'] == event)]\n",
        "#       # print(temp)\n",
        "#       # event_tuple = temp['EVENT_TYPE'].value_counts()\n",
        "#       for i in temp.index:\n",
        "#         if data.loc[i, 'EVENT_TYPE'] == event:\n",
        "#           # for event, val in event_tuple.items():\n",
        "#           tempdata.loc[i, 'COUNT'] = len(temp.index) \n",
        "#     count+=1\n",
        "#     print(count)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtqkPpUQoIVs"
      },
      "source": [
        "# tempdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpgCelvhADsZ"
      },
      "source": [
        "# tempdata.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTdLRoULIbGV"
      },
      "source": [
        "# # FILL OUT MISSING VALS\n",
        "# tempdata.fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrVwXnUMU2FC"
      },
      "source": [
        "# tempdata.to_excel('ACLED_Data_PrototypeV4.3(locationwise).xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAFMxh33L47-"
      },
      "source": [
        "3.1 Test and Predict 2020 only for Tableau Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5viig1FJL4KQ",
        "outputId": "8ae38695-88e8-46b8-fb3a-51ff3969838a"
      },
      "source": [
        "# # DISTRICTS\n",
        "# data2 = pd.read_excel('/content/gdrive/MyDrive/Thesis Mates/Thesis Part 2/ACLED Data & Paper Writing Guideline /Datasets/ACLED_Data_PrototypeV4.3(locationwise).xlsx')\n",
        "# data2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>DISTRICT</th>\n",
              "      <th>COUNT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Lohagara</td>\n",
              "      <td>NARAIL</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Hathazari</td>\n",
              "      <td>CHITTAGONG</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rangamati</td>\n",
              "      <td>RANGAMATI HILL</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajoir</td>\n",
              "      <td>MADARIPUR</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajshahi</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11119</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Sadarpur</td>\n",
              "      <td>FARIDPUR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11120</th>\n",
              "      <td>2020</td>\n",
              "      <td>ViolenceAgainstCivilians</td>\n",
              "      <td>Chandpur</td>\n",
              "      <td>CHANDPUR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11121</th>\n",
              "      <td>2020</td>\n",
              "      <td>ViolenceAgainstCivilians</td>\n",
              "      <td>Madhukhali</td>\n",
              "      <td>FARIDPUR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11122</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Paba</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11123</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bhuapur</td>\n",
              "      <td>TANGAIL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11124 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       YEAR                EVENT_TYPE    LOCATION        DISTRICT  COUNT\n",
              "0      2001                   Battles    Lohagara          NARAIL      4\n",
              "1      2001                     Riots   Hathazari      CHITTAGONG      7\n",
              "2      2001                     Riots   Rangamati  RANGAMATI HILL      6\n",
              "3      2001                     Riots      Rajoir       MADARIPUR      2\n",
              "4      2001                     Riots    Rajshahi        RAJSHAHI     31\n",
              "...     ...                       ...         ...             ...    ...\n",
              "11119  2020                     Riots    Sadarpur        FARIDPUR      1\n",
              "11120  2020  ViolenceAgainstCivilians    Chandpur        CHANDPUR      1\n",
              "11121  2020  ViolenceAgainstCivilians  Madhukhali        FARIDPUR      1\n",
              "11122  2020                     Riots        Paba        RAJSHAHI      1\n",
              "11123  2020                     Riots     Bhuapur         TANGAIL      1\n",
              "\n",
              "[11124 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1474
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLocYnVBhHDs"
      },
      "source": [
        "TEST PREDICT ALL REGRESSION MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCXk_pK7jxHs"
      },
      "source": [
        "# def modelize(X_train, X_test, y_train, y_test, models, single): # (singles) argument optional\n",
        "#   # ENCODIZE \n",
        "#   le= LabelEncoder()\n",
        "#   # le = OneHotEncoder(categories='auto')\n",
        "\n",
        "#   le_X_train = pd.DataFrame()\n",
        "#   le_X_test = pd.DataFrame()\n",
        "#   le_singles = pd.DataFrame()\n",
        "\n",
        "\n",
        "#   for col in X_train.columns:\n",
        "#     if (is_string_dtype(X_train[col].dtype)):\n",
        "#       # CAN ALSO USE ONE HOT INSTEAD\n",
        "#       if col == 'LOCATION': # TOO MANY LOCATIONS\n",
        "#         uniques = data2['LOCATION'].unique()\n",
        "#         le.fit(uniques)\n",
        "#         le_X_train[col] = le.transform(X_train[col].values.reshape(-1, 1))\n",
        "#         le_X_test[col] = le.transform(X_test[col].values.reshape(-1, 1))\n",
        "#         le_singles[col] = le.transform(singles[col].values.reshape(-1, 1))\n",
        "#       else:\n",
        "#         le_X_train[col] = le.fit_transform(X_train[col].values.reshape(-1, 1))\n",
        "#         le_X_test[col] = le.transform(X_test[col].values.reshape(-1, 1))\n",
        "#         le_singles[col] = le.transform(singles[col].values.reshape(-1, 1))\n",
        "#     else:\n",
        "#       # ms.fit(x_train[[col]])\n",
        "#       le_X_train[col] = X_train[col].copy()\n",
        "#       le_X_test[col] = X_test[col].copy()\n",
        "#       le_singles[col] = singles[col].copy()\n",
        "\n",
        "#   # print(le_X_train['DISTRICT'])\n",
        "\n",
        "#   count = 0\n",
        "#   for name, model in models:\n",
        "#     regr = model.fit(le_X_train, y_train.values.ravel())\n",
        "#     predictions = regr.predict(le_X_test)\n",
        "    \n",
        "#     count+=1\n",
        "#     # R2 HIGHER BETTER, MSE LOWER BETTER\n",
        "#     print(count,'',name, 'R2 Score: ', round(r2_score(y_test, predictions),3), 'MSE: ', round(mean_squared_error(y_test, predictions, squared= False),3))\n",
        "\n",
        "#     # print('TRUE: ',y_test.values.tolist())\n",
        "#     # print('PREDICTED: ', *predictions)\n",
        "#     # print('\\n')\n",
        "\n",
        "#     if name == 'Random Forest':\n",
        "#       singlesprediction = regr.predict(le_singles)\n",
        "#       print('~~~~~~~~~~~~')\n",
        "#       print('Single Data: ',singles)\n",
        "#       print('Prediction',singlesprediction)\n",
        "#       print('~~~~~~~~~~~~')\n",
        "\n",
        "#     return predictions # for 2020 Predictions\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8hZ_hXX1w8h"
      },
      "source": [
        "# # ALL MODELS train test split\n",
        "\n",
        "# X = data2.loc[:, data2.columns != 'COUNT']\n",
        "# y = data2.loc[:, data2.columns == 'COUNT']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "# models = [('Decision Tree', DecisionTreeRegressor(random_state=None)),\n",
        "#           ('Random Forest', RandomForestRegressor(max_depth=4, random_state=None)),\n",
        "#           ('SVR', make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))),\n",
        "#           ('MLP', make_pipeline(StandardScaler(), MLPRegressor(random_state=None, max_iter = 100000, learning_rate_init=0.001))),\n",
        "#           ('Lasso', linear_model.Lasso(alpha=0.1)),\n",
        "#           ('Bayesian', linear_model.BayesianRidge()),\n",
        "#           ('Ridge', linear_model.Ridge()),\n",
        "#           ('Linear Regression', LinearRegression())\n",
        "#           ]\n",
        "\n",
        "\n",
        "# # SINGLE DATA PREDICT\n",
        "# single = [[2021,'Riots','Bhuapur','TANGAIL'],\n",
        "#           [2021,'ViolenceAgainstCivilians','Chandpur','CHANDPUR']]\n",
        "# singles = pd.DataFrame(single, columns = ['YEAR', 'EVENT_TYPE','LOCATION','DISTRICT'])\n",
        "# modelize(X_train, X_test, y_train, y_test, models,singles)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMWzduXDhLVx"
      },
      "source": [
        "PREDICT 2020 ONLY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey2JNv62Prvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ef9164-c7ea-4093-9a7b-ede47271d6b2"
      },
      "source": [
        "# # 2020 ONLY\n",
        "\n",
        "# train = data2.loc[(data2['YEAR'] != 2020)]\n",
        "# test = data2.loc[(data2['YEAR'] == 2020)]\n",
        "\n",
        "# X_train = train.loc[:, data2.columns != 'COUNT']\n",
        "# X_test = test.loc[:, data2.columns != 'COUNT']\n",
        "# y_train = train.loc[:, data2.columns == 'COUNT']\n",
        "# y_test = test.loc[:, data2.columns == 'COUNT']\n",
        "\n",
        "# models = [\n",
        "#           # ('MLP', make_pipeline(StandardScaler(), MLPRegressor(random_state=None, max_iter = 100000, learning_rate_init=0.001)))\n",
        "#           ('Random Forest', RandomForestRegressor(max_depth=6, random_state=0))\n",
        "#           ]\n",
        "\n",
        "\n",
        "# # SINGLE DATA PREDICT NOT NEEDED\n",
        "# single = [[2021,'Riots','Bhuapur','TANGAIL'],\n",
        "#           [2021,'ViolenceAgainstCivilians','Chandpur','CHANDPUR']]\n",
        "# singles = pd.DataFrame(single, columns = ['YEAR', 'EVENT_TYPE','LOCATION','DISTRICT'])\n",
        "\n",
        "# y_pred = modelize(X_train, X_test, y_train, y_test, models,singles)\n",
        "\n",
        "# temp_data = test\n",
        "# temp_data.loc[:, 'Predictions'] = y_pred\n",
        "\n",
        "# temp_data.to_excel('ACLED_2020_Prediction_Counts.xlsx',index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1  Random Forest R2 Score:  0.564 MSE:  8.94\n",
            "~~~~~~~~~~~~\n",
            "Single Data:     YEAR                EVENT_TYPE  LOCATION  DISTRICT\n",
            "0  2021                     Riots   Bhuapur   TANGAIL\n",
            "1  2021  ViolenceAgainstCivilians  Chandpur  CHANDPUR\n",
            "Prediction [1.2505834  3.22582301]\n",
            "~~~~~~~~~~~~\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[key] = _infer_fill_value(value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B51WJKxajfl9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpTc5GTgQ96I"
      },
      "source": [
        "# DONT NEED ANYMORE?\n",
        "\n",
        "# le= LabelEncoder()\n",
        "# ms_train_x = pd.DataFrame()\n",
        "# ms_test_x = pd.DataFrame()\n",
        "# # LABEL ENCODER + Min max Scaler\n",
        "# for col in x_train.columns:\n",
        "#   if (is_string_dtype(x_train[col].dtype)):\n",
        "#     uniques = x_train[col].unique() # Do this otherwise test doesnt get enough labels to labelencode\n",
        "#     le.fit(uniques)\n",
        "#     ms_train_x[col] = le.transform(x_train[[col]]).flatten() # flatten otherwise 1d doesnt work as numpy array\n",
        "#     ms_test_x[col] = le.transform(x_test[[col]]).flatten()\n",
        "#   else:\n",
        "#     # ms.fit(x_train[[col]])\n",
        "#     ms_train_x[col] = x_train[col].copy()\n",
        "#     ms_test_x[col] = x_test[col].copy()\n",
        "\n",
        "# regr = MLPRegressor(random_state=1, max_iter=2000).fit(ms_train_x, y_train)\n",
        "# y_pred = regr.predict(ms_test_x)\n",
        "# print(mean_squared_error(y_test, y_pred, squared=False))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW3mnkkvUxjf"
      },
      "source": [
        "# tableau_prototype_2021 = temp_data.loc[(temp_data['YEAR'] == 2020)]\n",
        "# tableau_prototype_2021['PRED_Riots'] = y_pred.astype(int).tolist()\n",
        "# tableau_prototype_2021\n",
        "# tableau_prototype_2021.to_excel('tableau_prototype_predict_totals_riots_2021.xlsx',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYceVJlWTqcc"
      },
      "source": [
        "K Means Districts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "NiYMtgSBTsuh",
        "outputId": "0112db87-574d-45e1-c7fb-ae1069c4b334"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>EVENT_TYPE</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>DISTRICT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>Battles</td>\n",
              "      <td>Lohagara</td>\n",
              "      <td>23.1998</td>\n",
              "      <td>89.6644</td>\n",
              "      <td>NARAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Hathazari</td>\n",
              "      <td>22.5052</td>\n",
              "      <td>91.8134</td>\n",
              "      <td>CHITTAGONG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rangamati</td>\n",
              "      <td>22.6432</td>\n",
              "      <td>92.1919</td>\n",
              "      <td>RANGAMATI HILL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajoir</td>\n",
              "      <td>23.1878</td>\n",
              "      <td>90.0322</td>\n",
              "      <td>MADARIPUR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Rajshahi</td>\n",
              "      <td>24.3740</td>\n",
              "      <td>88.6011</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30624</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Paba</td>\n",
              "      <td>24.4417</td>\n",
              "      <td>88.6278</td>\n",
              "      <td>RAJSHAHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30625</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bhuapur</td>\n",
              "      <td>24.4604</td>\n",
              "      <td>89.8727</td>\n",
              "      <td>TANGAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30626</th>\n",
              "      <td>2020</td>\n",
              "      <td>Protests</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7406</td>\n",
              "      <td>90.3943</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30627</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Bogra</td>\n",
              "      <td>24.8510</td>\n",
              "      <td>89.3711</td>\n",
              "      <td>BOGRA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30628</th>\n",
              "      <td>2020</td>\n",
              "      <td>Riots</td>\n",
              "      <td>Dhaka</td>\n",
              "      <td>23.7333</td>\n",
              "      <td>90.4000</td>\n",
              "      <td>DHAKA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30629 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       YEAR EVENT_TYPE   LOCATION  LATITUDE  LONGITUDE        DISTRICT\n",
              "0      2001    Battles   Lohagara   23.1998    89.6644          NARAIL\n",
              "1      2001      Riots  Hathazari   22.5052    91.8134      CHITTAGONG\n",
              "2      2001      Riots  Rangamati   22.6432    92.1919  RANGAMATI HILL\n",
              "3      2001      Riots     Rajoir   23.1878    90.0322       MADARIPUR\n",
              "4      2001      Riots   Rajshahi   24.3740    88.6011        RAJSHAHI\n",
              "...     ...        ...        ...       ...        ...             ...\n",
              "30624  2020      Riots       Paba   24.4417    88.6278        RAJSHAHI\n",
              "30625  2020      Riots    Bhuapur   24.4604    89.8727         TANGAIL\n",
              "30626  2020   Protests     Dhaka    23.7406    90.3943           DHAKA\n",
              "30627  2020      Riots      Bogra   24.8510    89.3711           BOGRA\n",
              "30628  2020      Riots     Dhaka    23.7333    90.4000           DHAKA\n",
              "\n",
              "[30629 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qBAvy_cUjFz"
      },
      "source": [
        "# # TRAIN WHOLE DATASET AND CLUSTER\n",
        "\n",
        "# from sklearn.cluster import KMeans\n",
        "# plt.rcParams[\"figure.figsize\"] = (5,5)\n",
        "\n",
        "# train = data[['LONGITUDE', 'LATITUDE']]\n",
        "\n",
        "# km = KMeans(n_clusters=64, init='random')\n",
        "\n",
        "# # GRAPH BEFORE TRAINING\n",
        "# train_plot = pd.DataFrame(train)\n",
        "# train_plot.plot.scatter(x=0, y=1, colormap='jet', title='Before Training')\n",
        "\n",
        "# # TRAIN\n",
        "# km.fit(train)\n",
        "\n",
        "# # PREDICT\n",
        "# prediction = km.predict(train)\n",
        "\n",
        "# # GRAPH AFTER CLUSTERING\n",
        "# train_plot = pd.DataFrame(train)\n",
        "# train_plot['cluster_index'] = pd.Series(prediction)\n",
        "# train_plot.plot.scatter(x=0, y=1, c='cluster_index', colormap='jet', title='After Clustering')\n",
        "\n",
        "# print(len(np.unique(prediction))) # unique clusters"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}